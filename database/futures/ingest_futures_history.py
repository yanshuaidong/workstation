#!/usr/bin/env python3
"""
æœŸè´§å†å²æ•°æ®å…¥åº“å·¥å…·

ä» AkShare è·å–æœŸè´§ä¸»è¿å†å²è¡Œæƒ…æ•°æ®å¹¶å­˜å…¥ SQLite æ•°æ®åº“
é»˜è®¤æ—¥æœŸèŒƒå›´: 2018-01-01 ~ 2024-12-31

ä½¿ç”¨æ–¹æ³•:
    # è·å–å•ä¸ªå“ç§ (ä½¿ç”¨é»˜è®¤æ—¥æœŸ)
    python ingest_futures_history.py --symbol aum
    
    # è·å–å¤šä¸ªå“ç§
    python ingest_futures_history.py --symbol aum,cum,rbm
    
    # è·å–æ‰€æœ‰å“ç§
    python ingest_futures_history.py --all
    
    # æŒ‡å®šæ—¥æœŸèŒƒå›´
    python ingest_futures_history.py --symbol aum --start 2023-01-01 --end 2023-12-31
    
    # åˆ—å‡ºæ‰€æœ‰å¯ç”¨å“ç§
    python ingest_futures_history.py --list
"""

import os
import json
import sqlite3
import argparse
from datetime import datetime
from typing import Optional, List, Dict, Any

import akshare as ak
import pandas as pd


# è„šæœ¬æ‰€åœ¨ç›®å½•
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
# æ•°æ®åº“è·¯å¾„
DB_PATH = os.path.join(SCRIPT_DIR, 'futures.db')
# æ˜ å°„æ–‡ä»¶è·¯å¾„
MAPPING_PATH = os.path.join(SCRIPT_DIR, 'futures_mapping.json')
# æ—¥å¿—æ–‡ä»¶è·¯å¾„
LOG_PATH = os.path.join(SCRIPT_DIR, 'ingest_futures.log')


def write_log(message: str):
    """å†™å…¥æ—¥å¿—æ–‡ä»¶"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    with open(LOG_PATH, 'a', encoding='utf-8') as f:
        f.write(f"[{timestamp}] {message}\n")


def load_mapping() -> Dict[str, Any]:
    """åŠ è½½æœŸè´§å“ç§æ˜ å°„é…ç½®"""
    with open(MAPPING_PATH, 'r', encoding='utf-8') as f:
        return json.load(f)


def get_db_connection() -> sqlite3.Connection:
    """è·å–æ•°æ®åº“è¿æ¥"""
    conn = sqlite3.connect(DB_PATH)
    conn.execute("PRAGMA journal_mode=WAL")
    conn.execute("PRAGMA synchronous=NORMAL")
    return conn


def create_history_table(conn: sqlite3.Connection, table_name: str):
    """
    åˆ›å»ºå†å²è¡Œæƒ…æ•°æ®è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    
    Args:
        conn: æ•°æ®åº“è¿æ¥
        table_name: è¡¨å (å¦‚ hist_aum)
    """
    sql = f"""
    CREATE TABLE IF NOT EXISTS {table_name} (
        trade_date TEXT PRIMARY KEY,
        -- ä»·æ ¼æ•°æ®
        open_price REAL,
        high_price REAL,
        low_price REAL,
        close_price REAL,
        price_change REAL,
        change_pct REAL,
        -- æˆäº¤æ•°æ®
        volume INTEGER,
        open_interest INTEGER,
        turnover REAL,
        -- æŠ€æœ¯æŒ‡æ ‡ - MACD
        macd_dif REAL,
        macd_dea REAL,
        macd_histogram REAL,
        -- æŠ€æœ¯æŒ‡æ ‡ - RSI
        rsi_14 REAL,
        -- æŠ€æœ¯æŒ‡æ ‡ - KDJ
        kdj_k REAL,
        kdj_d REAL,
        kdj_j REAL,
        -- æŠ€æœ¯æŒ‡æ ‡ - å¸ƒæ—å¸¦
        bb_upper REAL,
        bb_middle REAL,
        bb_lower REAL,
        bb_width REAL,
        -- å…¶ä»–
        recommendation TEXT,
        source_ts TEXT,
        ingest_ts TEXT
    )
    """
    conn.execute(sql)
    conn.commit()


def fetch_futures_data(api_symbol: str, start_date: str, end_date: str) -> Optional[pd.DataFrame]:
    """
    ä» AkShare è·å–æœŸè´§å†å²æ•°æ®
    
    Args:
        api_symbol: AkShare API ä½¿ç”¨çš„ä»£ç  (å¦‚ AU0)
        start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        
    Returns:
        DataFrame æˆ– None
    """
    try:
        # è·å–æœŸè´§ä¸»è¿æ•°æ®
        df = ak.futures_main_sina(symbol=api_symbol)
        
        if df is None or df.empty:
            return None
        
        # é‡å‘½ååˆ—ï¼ˆAkShare è¿”å›ä¸­æ–‡åˆ—åï¼‰
        column_mapping = {
            'æ—¥æœŸ': 'trade_date',
            'å¼€ç›˜ä»·': 'open_price',
            'æœ€é«˜ä»·': 'high_price',
            'æœ€ä½ä»·': 'low_price',
            'æ”¶ç›˜ä»·': 'close_price',
            'æˆäº¤é‡': 'volume',
            'æŒä»“é‡': 'open_interest',
        }
        
        for cn_col, en_col in column_mapping.items():
            if cn_col in df.columns:
                df.rename(columns={cn_col: en_col}, inplace=True)
        
        # æ ¼å¼åŒ–æ—¥æœŸ
        if 'trade_date' in df.columns:
            df['trade_date'] = pd.to_datetime(df['trade_date']).dt.strftime('%Y-%m-%d')
        
        # æŒ‰æ—¥æœŸèŒƒå›´è¿‡æ»¤
        df_filtered = df[(df['trade_date'] >= start_date) & (df['trade_date'] <= end_date)]
        
        if df_filtered.empty:
            return None
        
        # æŒ‰æ—¥æœŸæ’åº
        df_filtered = df_filtered.sort_values('trade_date').reset_index(drop=True)
        
        # æ·»åŠ å…¥åº“æ—¶é—´æˆ³
        df_filtered['ingest_ts'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        return df_filtered
        
    except Exception as e:
        write_log(f"FETCH_ERROR: {api_symbol} - {e}")
        return None


def insert_data(conn: sqlite3.Connection, table_name: str, df: pd.DataFrame) -> int:
    """
    å°†æ•°æ®æ’å…¥æ•°æ®åº“ï¼ˆä½¿ç”¨ REPLACE é¿å…ä¸»é”®å†²çªï¼‰
    
    Args:
        conn: æ•°æ®åº“è¿æ¥
        table_name: è¡¨å
        df: æ•°æ® DataFrame
        
    Returns:
        æ’å…¥çš„è®°å½•æ•°
    """
    # åªä¿ç•™è¡¨ä¸­å­˜åœ¨çš„åˆ—
    valid_columns = [
        'trade_date', 'open_price', 'high_price', 'low_price', 'close_price',
        'price_change', 'change_pct', 'volume', 'open_interest', 'turnover',
        'macd_dif', 'macd_dea', 'macd_histogram', 'rsi_14',
        'kdj_k', 'kdj_d', 'kdj_j',
        'bb_upper', 'bb_middle', 'bb_lower', 'bb_width',
        'recommendation', 'source_ts', 'ingest_ts'
    ]
    
    # ç­›é€‰å­˜åœ¨çš„åˆ—
    columns_to_insert = [col for col in valid_columns if col in df.columns]
    df_to_insert = df[columns_to_insert].copy()
    
    # æ„å»º INSERT OR REPLACE è¯­å¥
    columns_str = ', '.join(columns_to_insert)
    placeholders = ', '.join(['?' for _ in columns_to_insert])
    sql = f"INSERT OR REPLACE INTO {table_name} ({columns_str}) VALUES ({placeholders})"
    
    # æ‰¹é‡æ’å…¥
    cursor = conn.cursor()
    rows = df_to_insert.values.tolist()
    cursor.executemany(sql, rows)
    conn.commit()
    
    return len(rows)


def update_contracts_main(conn: sqlite3.Connection, symbol: str, name: str, exchange: str):
    """
    æ›´æ–°åˆçº¦ä¸»è¡¨
    
    Args:
        conn: æ•°æ®åº“è¿æ¥
        symbol: åˆçº¦ä»£ç  (å¦‚ aum)
        name: åˆçº¦åç§°
        exchange: äº¤æ˜“æ‰€ä»£ç 
    """
    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨
    cursor = conn.cursor()
    cursor.execute("SELECT symbol FROM contracts_main WHERE symbol = ?", (symbol.upper(),))
    exists = cursor.fetchone() is not None
    
    if exists:
        # æ›´æ–°
        cursor.execute("""
            UPDATE contracts_main 
            SET updated_at = ?
            WHERE symbol = ?
        """, (now, symbol.upper()))
    else:
        # æ’å…¥
        cursor.execute("""
            INSERT INTO contracts_main (symbol, name, exchange, is_active, created_at, updated_at)
            VALUES (?, ?, ?, 1, ?, ?)
        """, (symbol.upper(), name, exchange, now, now))
    
    conn.commit()


def ingest_symbol(symbol: str, start_date: str, end_date: str, mapping: Dict) -> bool:
    """
    å…¥åº“å•ä¸ªå“ç§çš„å†å²æ•°æ®
    
    Args:
        symbol: å“ç§ä»£ç  (å¦‚ aum)
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        mapping: æ˜ å°„é…ç½®
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    futures_config = mapping.get('futures', {})
    
    # å°è¯•å¤§å°å†™åŒ¹é…
    config = futures_config.get(symbol) or futures_config.get(symbol.lower()) or futures_config.get(symbol.upper())
    
    if not config:
        write_log(f"FAIL: {symbol} - æœªæ‰¾åˆ°å“ç§é…ç½®")
        print(f"  âŒ {symbol} - æœªæ‰¾åˆ°é…ç½®")
        return False
    
    name = config['name']
    api_symbol = config['api_symbol']
    db_table = config['db_table']
    exchange = config['exchange']
    
    # è·å–æ•°æ®
    df = fetch_futures_data(api_symbol, start_date, end_date)
    
    if df is None or df.empty:
        write_log(f"FAIL: {symbol} ({name}) -> {db_table} - æ— æ•°æ®")
        print(f"  âš ï¸ {symbol} ({name}) - æ— æ•°æ®")
        return False
    
    # å…¥åº“
    try:
        conn = get_db_connection()
        create_history_table(conn, db_table)
        count = insert_data(conn, db_table, df)
        update_contracts_main(conn, symbol, name, exchange)
        conn.close()
        
        write_log(f"OK: {symbol} ({name}) -> {db_table} - {count} æ¡")
        print(f"  âœ… {symbol} ({name}) -> {db_table} - {count} æ¡")
        return True
        
    except Exception as e:
        write_log(f"FAIL: {symbol} ({name}) -> {db_table} - {e}")
        print(f"  âŒ {symbol} ({name}) - å…¥åº“å¤±è´¥: {e}")
        return False


def list_symbols(mapping: Dict):
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æœŸè´§å“ç§"""
    print("\nğŸ“‹ å¯ç”¨æœŸè´§å“ç§åˆ—è¡¨:")
    print("-" * 70)
    print(f"{'ä»£ç ':<8} {'åç§°':<16} {'API Symbol':<10} {'äº¤æ˜“æ‰€':<8} {'æ•°æ®åº“è¡¨':<15}")
    print("-" * 70)
    
    futures = mapping.get('futures', {})
    exchanges = mapping.get('exchanges', {})
    
    for symbol, config in sorted(futures.items(), key=lambda x: x[0].lower()):
        exchange_name = exchanges.get(config['exchange'], config['exchange'])
        print(f"{symbol:<8} {config['name']:<16} {config['api_symbol']:<10} {exchange_name:<8} {config['db_table']:<15}")
    
    print("-" * 70)
    print(f"å…± {len(futures)} ä¸ªå“ç§")


def main():
    parser = argparse.ArgumentParser(
        description='æœŸè´§å†å²æ•°æ®å…¥åº“å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # è·å–æ²ªé‡‘ä¸»è¿æ•°æ® (ä½¿ç”¨é»˜è®¤æ—¥æœŸ 2018-01-01 ~ 2024-12-31)
  python ingest_futures_history.py --symbol aum
  
  # è·å–å¤šä¸ªå“ç§
  python ingest_futures_history.py --symbol aum,cum,rbm
  
  # è·å–æ‰€æœ‰å“ç§
  python ingest_futures_history.py --all
  
  # æŒ‡å®šæ—¥æœŸèŒƒå›´
  python ingest_futures_history.py --symbol aum --start 2023-01-01 --end 2023-12-31
  
  # åˆ—å‡ºæ‰€æœ‰å¯ç”¨å“ç§
  python ingest_futures_history.py --list
        """
    )
    
    parser.add_argument('--symbol', '-s', type=str,
                        help='å“ç§ä»£ç ï¼Œå¤šä¸ªç”¨é€—å·åˆ†éš” (å¦‚ aum,cum,rbm)')
    parser.add_argument('--start', type=str, default='2018-01-01',
                        help='å¼€å§‹æ—¥æœŸ (YYYY-MM-DD), é»˜è®¤: 2018-01-01')
    parser.add_argument('--end', type=str, default='2024-12-31',
                        help='ç»“æŸæ—¥æœŸ (YYYY-MM-DD), é»˜è®¤: 2024-12-31')
    parser.add_argument('--all', '-a', action='store_true',
                        help='è·å–æ‰€æœ‰å“ç§')
    parser.add_argument('--list', '-l', action='store_true',
                        help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨å“ç§')
    
    args = parser.parse_args()
    
    # åŠ è½½æ˜ å°„é…ç½®
    try:
        mapping = load_mapping()
    except FileNotFoundError:
        print(f"âŒ æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨: {MAPPING_PATH}")
        return 1
    except json.JSONDecodeError as e:
        print(f"âŒ æ˜ å°„æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
        return 1
    
    # åˆ—å‡ºå“ç§
    if args.list:
        list_symbols(mapping)
        return 0
    
    # æ£€æŸ¥å‚æ•°
    if not args.symbol and not args.all:
        parser.print_help()
        print("\nâŒ è¯·æŒ‡å®š --symbol æˆ– --all")
        return 1
    
    # ç¡®å®šè¦å¤„ç†çš„å“ç§åˆ—è¡¨
    if args.all:
        symbols = list(mapping.get('futures', {}).keys())
        print(f"\nğŸš€ å¼€å§‹è·å–æ‰€æœ‰ {len(symbols)} ä¸ªå“ç§çš„å†å²æ•°æ®...")
    else:
        symbols = [s.strip() for s in args.symbol.split(',')]
        print(f"\nğŸš€ å¼€å§‹è·å– {len(symbols)} ä¸ªå“ç§çš„å†å²æ•°æ®...")
    
    print(f"   æ—¥æœŸèŒƒå›´: {args.start} ~ {args.end}")
    print(f"   æ•°æ®åº“: {DB_PATH}")
    print(f"   æ—¥å¿—æ–‡ä»¶: {LOG_PATH}")
    print("=" * 60)
    
    # å†™å…¥æ—¥å¿—å¤´
    write_log("=" * 50)
    write_log(f"å¼€å§‹å…¥åº“: {len(symbols)} ä¸ªå“ç§, æ—¥æœŸ: {args.start} ~ {args.end}")
    
    # å¤„ç†æ¯ä¸ªå“ç§
    success_count = 0
    fail_count = 0
    failed_symbols = []
    
    for symbol in symbols:
        if ingest_symbol(symbol, args.start, args.end, mapping):
            success_count += 1
        else:
            fail_count += 1
            failed_symbols.append(symbol)
    
    # å†™å…¥æ±‡æ€»æ—¥å¿—
    write_log(f"å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {fail_count}")
    if failed_symbols:
        write_log(f"å¤±è´¥åˆ—è¡¨: {', '.join(failed_symbols)}")
    write_log("=" * 50)
    
    # æ‰§è¡Œ WAL checkpointï¼Œåˆå¹¶ WAL æ–‡ä»¶åˆ°ä¸»æ•°æ®åº“
    try:
        conn = get_db_connection()
        conn.execute("PRAGMA wal_checkpoint(TRUNCATE)")
        conn.close()
    except Exception as e:
        write_log(f"WAL checkpoint å¤±è´¥: {e}")
    
    # æ±‡æ€»
    print("=" * 60)
    print(f"âœ… å®Œæˆ! æˆåŠŸ: {success_count}, å¤±è´¥: {fail_count}")
    if failed_symbols:
        print(f"âŒ å¤±è´¥å“ç§: {', '.join(failed_symbols)}")
    
    return 0 if fail_count == 0 else 1


if __name__ == '__main__':
    exit(main())
