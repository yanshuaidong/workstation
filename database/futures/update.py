#!/usr/bin/env python3
"""
æœŸè´§å†å²æ•°æ®å¢é‡æ›´æ–°å·¥å…·

è‡ªåŠ¨æŸ¥è¯¢æ•°æ®åº“ä¸­å„å“ç§çš„æœ€æ–°æ—¥æœŸï¼Œå¹¶ä» AkShare è·å–å¢é‡æ•°æ®æ›´æ–°åˆ°æœ€æ–°

ä½¿ç”¨æ–¹æ³•:
    # æ›´æ–°æ‰€æœ‰å“ç§
    python update.py
    
    # æ›´æ–°æŒ‡å®šå“ç§
    python update.py --symbol aum,cum,rbm
    
    # é¢„è§ˆæ¨¡å¼ï¼ˆåªæ˜¾ç¤ºéœ€è¦æ›´æ–°çš„æ•°æ®ï¼Œä¸å®é™…æ›´æ–°ï¼‰
    python update.py --dry-run
    
    # æ˜¾ç¤ºæ‰€æœ‰å“ç§çš„æœ€æ–°æ•°æ®æ—¥æœŸ
    python update.py --status
"""

import os
import json
import sqlite3
import argparse
from datetime import datetime, timedelta
from typing import Optional, Dict, Any, List, Tuple
from contextlib import contextmanager

import akshare as ak
import pandas as pd


# è„šæœ¬æ‰€åœ¨ç›®å½•
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
# æ•°æ®åº“è·¯å¾„
DB_PATH = os.path.join(SCRIPT_DIR, 'futures.db')
# æ˜ å°„æ–‡ä»¶è·¯å¾„ï¼ˆåœ¨ tools ç›®å½•ä¸‹ï¼‰
MAPPING_PATH = os.path.join(SCRIPT_DIR, '..', '..', 'tools', 'è·å–æœŸè´§æ•°æ®', 'futures_mapping.json')
# æ—¥å¿—æ–‡ä»¶è·¯å¾„
LOG_PATH = os.path.join(SCRIPT_DIR, 'update.log')


def write_log(message: str):
    """å†™å…¥æ—¥å¿—æ–‡ä»¶"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    with open(LOG_PATH, 'a', encoding='utf-8') as f:
        f.write(f"[{timestamp}] {message}\n")


def load_mapping() -> Dict[str, Any]:
    """åŠ è½½æœŸè´§å“ç§æ˜ å°„é…ç½®"""
    with open(MAPPING_PATH, 'r', encoding='utf-8') as f:
        return json.load(f)


@contextmanager
def get_db_connection():
    """è·å–æ•°æ®åº“è¿æ¥ï¼ˆä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œè‡ªåŠ¨å…³é—­ï¼‰"""
    conn = sqlite3.connect(DB_PATH)
    conn.execute("PRAGMA journal_mode=WAL")
    conn.execute("PRAGMA synchronous=NORMAL")
    try:
        yield conn
    finally:
        conn.close()


def get_all_hist_tables(conn: sqlite3.Connection) -> List[str]:
    """è·å–æ‰€æœ‰å†å²æ•°æ®è¡¨å"""
    cursor = conn.cursor()
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'hist_%'")
    return [row[0] for row in cursor.fetchall()]


def get_latest_date(conn: sqlite3.Connection, table_name: str) -> Optional[str]:
    """
    è·å–æŒ‡å®šè¡¨çš„æœ€æ–°äº¤æ˜“æ—¥æœŸ
    
    Args:
        conn: æ•°æ®åº“è¿æ¥
        table_name: è¡¨å (å¦‚ hist_aum)
        
    Returns:
        æœ€æ–°æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD) æˆ– None
    """
    cursor = conn.cursor()
    try:
        cursor.execute(f"SELECT MAX(trade_date) FROM {table_name}")
        result = cursor.fetchone()
        return result[0] if result and result[0] else None
    except sqlite3.OperationalError:
        return None


def get_all_latest_dates(conn: sqlite3.Connection, mapping: Dict) -> Dict[str, Tuple[str, str, Optional[str]]]:
    """
    è·å–æ‰€æœ‰å“ç§çš„æœ€æ–°æ—¥æœŸ
    
    Returns:
        Dict: {symbol: (name, table_name, latest_date)}
    """
    futures = mapping.get('futures', {})
    result = {}
    
    for symbol, config in futures.items():
        table_name = config['db_table']
        name = config['name']
        latest_date = get_latest_date(conn, table_name)
        result[symbol] = (name, table_name, latest_date)
    
    return result


def fetch_futures_data(api_symbol: str, start_date: str, end_date: str) -> Optional[pd.DataFrame]:
    """
    ä» AkShare è·å–æœŸè´§å†å²æ•°æ®
    
    Args:
        api_symbol: AkShare API ä½¿ç”¨çš„ä»£ç  (å¦‚ AU0)
        start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        
    Returns:
        DataFrame æˆ– None
    """
    try:
        # è·å–æœŸè´§ä¸»è¿æ•°æ®
        df = ak.futures_main_sina(symbol=api_symbol)
        
        if df is None or df.empty:
            return None
        
        # é‡å‘½ååˆ—ï¼ˆAkShare è¿”å›ä¸­æ–‡åˆ—åï¼‰
        column_mapping = {
            'æ—¥æœŸ': 'trade_date',
            'å¼€ç›˜ä»·': 'open_price',
            'æœ€é«˜ä»·': 'high_price',
            'æœ€ä½ä»·': 'low_price',
            'æ”¶ç›˜ä»·': 'close_price',
            'æˆäº¤é‡': 'volume',
            'æŒä»“é‡': 'open_interest',
        }
        
        for cn_col, en_col in column_mapping.items():
            if cn_col in df.columns:
                df.rename(columns={cn_col: en_col}, inplace=True)
        
        # æ ¼å¼åŒ–æ—¥æœŸ
        if 'trade_date' in df.columns:
            df['trade_date'] = pd.to_datetime(df['trade_date']).dt.strftime('%Y-%m-%d')
        
        # æŒ‰æ—¥æœŸèŒƒå›´è¿‡æ»¤ï¼ˆåªå–å¼€å§‹æ—¥æœŸä¹‹åçš„æ•°æ®ï¼‰
        df_filtered = df[(df['trade_date'] > start_date) & (df['trade_date'] <= end_date)]
        
        if df_filtered.empty:
            return None
        
        # æŒ‰æ—¥æœŸæ’åº
        df_filtered = df_filtered.sort_values('trade_date').reset_index(drop=True)
        
        # æ·»åŠ å…¥åº“æ—¶é—´æˆ³
        df_filtered['ingest_ts'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        return df_filtered
        
    except Exception as e:
        write_log(f"FETCH_ERROR: {api_symbol} - {e}")
        return None


def insert_data(conn: sqlite3.Connection, table_name: str, df: pd.DataFrame) -> int:
    """
    å°†æ•°æ®æ’å…¥æ•°æ®åº“ï¼ˆä½¿ç”¨ REPLACE é¿å…ä¸»é”®å†²çªï¼‰
    
    Args:
        conn: æ•°æ®åº“è¿æ¥
        table_name: è¡¨å
        df: æ•°æ® DataFrame
        
    Returns:
        æ’å…¥çš„è®°å½•æ•°
    """
    # åªä¿ç•™è¡¨ä¸­å­˜åœ¨çš„åˆ—
    valid_columns = [
        'trade_date', 'open_price', 'high_price', 'low_price', 'close_price',
        'price_change', 'change_pct', 'volume', 'open_interest', 'turnover',
        'macd_dif', 'macd_dea', 'macd_histogram', 'rsi_14',
        'kdj_k', 'kdj_d', 'kdj_j',
        'bb_upper', 'bb_middle', 'bb_lower', 'bb_width',
        'recommendation', 'source_ts', 'ingest_ts'
    ]
    
    # ç­›é€‰å­˜åœ¨çš„åˆ—
    columns_to_insert = [col for col in valid_columns if col in df.columns]
    df_to_insert = df[columns_to_insert].copy()
    
    # æ„å»º INSERT OR REPLACE è¯­å¥
    columns_str = ', '.join(columns_to_insert)
    placeholders = ', '.join(['?' for _ in columns_to_insert])
    sql = f"INSERT OR REPLACE INTO {table_name} ({columns_str}) VALUES ({placeholders})"
    
    # æ‰¹é‡æ’å…¥
    cursor = conn.cursor()
    rows = df_to_insert.values.tolist()
    cursor.executemany(sql, rows)
    conn.commit()
    
    return len(rows)


def update_symbol(symbol: str, mapping: Dict, dry_run: bool = False) -> Tuple[bool, int, str]:
    """
    æ›´æ–°å•ä¸ªå“ç§çš„æ•°æ®
    
    Args:
        symbol: å“ç§ä»£ç  (å¦‚ aum)
        mapping: æ˜ å°„é…ç½®
        dry_run: æ˜¯å¦é¢„è§ˆæ¨¡å¼
        
    Returns:
        (æ˜¯å¦æˆåŠŸ, æ›´æ–°æ¡æ•°, æ¶ˆæ¯)
    """
    futures_config = mapping.get('futures', {})
    
    # å°è¯•å¤§å°å†™åŒ¹é…
    config = futures_config.get(symbol) or futures_config.get(symbol.lower()) or futures_config.get(symbol.upper())
    
    if not config:
        return False, 0, f"æœªæ‰¾åˆ°å“ç§é…ç½®: {symbol}"
    
    name = config['name']
    api_symbol = config['api_symbol']
    db_table = config['db_table']
    
    # è·å–æ•°æ®åº“ä¸­çš„æœ€æ–°æ—¥æœŸ
    with get_db_connection() as conn:
        latest_date = get_latest_date(conn, db_table)
    
    if not latest_date:
        return False, 0, f"{symbol} ({name}) - è¡¨ä¸å­˜åœ¨æˆ–æ— æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œåˆå§‹å…¥åº“"
    
    # è®¡ç®—æ›´æ–°èŒƒå›´ï¼šä»æœ€æ–°æ—¥æœŸåˆ°ä»Šå¤©
    today = datetime.now().strftime('%Y-%m-%d')
    
    if latest_date >= today:
        return True, 0, f"{symbol} ({name}) - å·²æ˜¯æœ€æ–° ({latest_date})"
    
    if dry_run:
        return True, 0, f"{symbol} ({name}) - éœ€è¦æ›´æ–°: {latest_date} -> {today}"
    
    # è·å–å¢é‡æ•°æ®
    df = fetch_futures_data(api_symbol, latest_date, today)
    
    if df is None or df.empty:
        write_log(f"NO_NEW_DATA: {symbol} ({name}) - {latest_date} ä¹‹åæ— æ–°æ•°æ®")
        return True, 0, f"{symbol} ({name}) - æ— æ–°æ•°æ® ({latest_date})"
    
    # æ’å…¥æ•°æ®
    try:
        with get_db_connection() as conn:
            count = insert_data(conn, db_table, df)
        
        new_latest = df['trade_date'].max()
        write_log(f"OK: {symbol} ({name}) -> {db_table} - æ–°å¢ {count} æ¡ ({latest_date} -> {new_latest})")
        return True, count, f"{symbol} ({name}) - æ–°å¢ {count} æ¡ ({latest_date} -> {new_latest})"
        
    except Exception as e:
        write_log(f"FAIL: {symbol} ({name}) - {e}")
        return False, 0, f"{symbol} ({name}) - æ›´æ–°å¤±è´¥: {e}"


def show_status(mapping: Dict):
    """æ˜¾ç¤ºæ‰€æœ‰å“ç§çš„æ•°æ®çŠ¶æ€"""
    with get_db_connection() as conn:
        all_dates = get_all_latest_dates(conn, mapping)
    
    print("\nğŸ“Š æœŸè´§æ•°æ®çŠ¶æ€:")
    print("-" * 80)
    print(f"{'å“ç§':<8} {'åç§°':<16} {'æ•°æ®åº“è¡¨':<15} {'æœ€æ–°æ—¥æœŸ':<12} {'çŠ¶æ€':<10}")
    print("-" * 80)
    
    today = datetime.now().strftime('%Y-%m-%d')
    yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
    
    need_update = 0
    no_data = 0
    up_to_date = 0
    
    for symbol, (name, table_name, latest_date) in sorted(all_dates.items(), key=lambda x: x[0].lower()):
        if latest_date is None:
            status = "âŒ æ— æ•°æ®"
            no_data += 1
        elif latest_date >= yesterday:
            status = "âœ… æœ€æ–°"
            up_to_date += 1
        else:
            days_behind = (datetime.strptime(today, '%Y-%m-%d') - datetime.strptime(latest_date, '%Y-%m-%d')).days
            status = f"âš ï¸ è½å{days_behind}å¤©"
            need_update += 1
        
        date_str = latest_date if latest_date else "-"
        print(f"{symbol:<8} {name:<16} {table_name:<15} {date_str:<12} {status:<10}")
    
    print("-" * 80)
    print(f"ğŸ“ˆ ç»Ÿè®¡: æœ€æ–° {up_to_date}, éœ€æ›´æ–° {need_update}, æ— æ•°æ® {no_data}, å…± {len(all_dates)} ä¸ªå“ç§")


def main():
    parser = argparse.ArgumentParser(
        description='æœŸè´§å†å²æ•°æ®å¢é‡æ›´æ–°å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # æ›´æ–°æ‰€æœ‰å“ç§
  python update.py
  
  # æ›´æ–°æŒ‡å®šå“ç§
  python update.py --symbol aum,cum,rbm
  
  # é¢„è§ˆæ¨¡å¼ï¼ˆåªæ˜¾ç¤ºéœ€è¦æ›´æ–°çš„æ•°æ®ï¼Œä¸å®é™…æ›´æ–°ï¼‰
  python update.py --dry-run
  
  # æ˜¾ç¤ºæ‰€æœ‰å“ç§çš„æœ€æ–°æ•°æ®æ—¥æœŸ
  python update.py --status
        """
    )
    
    parser.add_argument('--symbol', '-s', type=str,
                        help='å“ç§ä»£ç ï¼Œå¤šä¸ªç”¨é€—å·åˆ†éš” (å¦‚ aum,cum,rbm)')
    parser.add_argument('--status', action='store_true',
                        help='æ˜¾ç¤ºæ‰€æœ‰å“ç§çš„æ•°æ®çŠ¶æ€')
    parser.add_argument('--dry-run', '-n', action='store_true',
                        help='é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…æ›´æ–°æ•°æ®')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(DB_PATH):
        print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {DB_PATH}")
        return 1
    
    # åŠ è½½æ˜ å°„é…ç½®
    try:
        mapping = load_mapping()
    except FileNotFoundError:
        print(f"âŒ æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨: {MAPPING_PATH}")
        return 1
    except json.JSONDecodeError as e:
        print(f"âŒ æ˜ å°„æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
        return 1
    
    # æ˜¾ç¤ºçŠ¶æ€
    if args.status:
        show_status(mapping)
        return 0
    
    # ç¡®å®šè¦æ›´æ–°çš„å“ç§
    if args.symbol:
        symbols = [s.strip() for s in args.symbol.split(',')]
    else:
        # è·å–æ•°æ®åº“ä¸­å·²æœ‰çš„è¡¨ï¼Œåªæ›´æ–°è¿™äº›å“ç§
        with get_db_connection() as conn:
            tables = get_all_hist_tables(conn)
        
        # ä»è¡¨åæå–å“ç§ä»£ç  (hist_aum -> aum)
        futures_config = mapping.get('futures', {})
        symbols = []
        for symbol, config in futures_config.items():
            if config['db_table'] in tables:
                symbols.append(symbol)
    
    if not symbols:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ›´æ–°çš„å“ç§")
        return 1
    
    # å¼€å§‹æ›´æ–°
    mode = "[é¢„è§ˆæ¨¡å¼] " if args.dry_run else ""
    print(f"\nğŸ”„ {mode}å¼€å§‹æ›´æ–° {len(symbols)} ä¸ªå“ç§...")
    print(f"   æ•°æ®åº“: {DB_PATH}")
    print(f"   æ—¥å¿—æ–‡ä»¶: {LOG_PATH}")
    print("=" * 70)
    
    # å†™å…¥æ—¥å¿—å¤´
    if not args.dry_run:
        write_log("=" * 50)
        write_log(f"å¼€å§‹å¢é‡æ›´æ–°: {len(symbols)} ä¸ªå“ç§")
    
    success_count = 0
    fail_count = 0
    total_new_records = 0
    failed_symbols = []
    
    for symbol in symbols:
        success, count, message = update_symbol(symbol, mapping, args.dry_run)
        print(f"  {message}")
        
        if success:
            success_count += 1
            total_new_records += count
        else:
            fail_count += 1
            failed_symbols.append(symbol)
    
    # å†™å…¥æ±‡æ€»æ—¥å¿—
    if not args.dry_run:
        write_log(f"å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {fail_count}, æ–°å¢ {total_new_records} æ¡")
        if failed_symbols:
            write_log(f"å¤±è´¥åˆ—è¡¨: {', '.join(failed_symbols)}")
        write_log("=" * 50)
        
        # æ‰§è¡Œ WAL checkpointï¼Œåˆå¹¶ WAL æ–‡ä»¶åˆ°ä¸»æ•°æ®åº“
        try:
            with get_db_connection() as conn:
                conn.execute("PRAGMA wal_checkpoint(TRUNCATE)")
        except Exception as e:
            write_log(f"WAL checkpoint å¤±è´¥: {e}")
    
    # æ±‡æ€»
    print("=" * 70)
    print(f"âœ… å®Œæˆ! æˆåŠŸ: {success_count}, å¤±è´¥: {fail_count}, æ–°å¢è®°å½•: {total_new_records} æ¡")
    if failed_symbols:
        print(f"âŒ å¤±è´¥å“ç§: {', '.join(failed_symbols)}")
    
    return 0 if fail_count == 0 else 1


if __name__ == '__main__':
    exit(main())
