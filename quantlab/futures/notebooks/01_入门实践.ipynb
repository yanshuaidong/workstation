{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸš€ æœºå™¨å­¦ä¹ é‡åŒ–ç­–ç•¥å…¥é—¨å®è·µ\n",
        "\n",
        "è¿™ä¸ªç¬”è®°æœ¬å°†å¸¦ä½ ç”¨ **æœ€ç®€åŒ–çš„ä»£ç ** ç†è§£æ•´ä¸ªæµç¨‹ã€‚\n",
        "\n",
        "**ç›®æ ‡**: åœ¨50è¡Œä»£ç å†…å®Œæˆä¸€ä¸ªå®Œæ•´çš„æœºå™¨å­¦ä¹ ç­–ç•¥\n",
        "\n",
        "---\n",
        "\n",
        "## å­¦ä¹ æµç¨‹\n",
        "\n",
        "1. åŠ è½½æ•°æ® â†’ 2. å®šä¹‰æ ‡ç­¾ â†’ 3. åˆ›å»ºç‰¹å¾ â†’ 4. è®­ç»ƒæ¨¡å‹ â†’ 5. è¯„ä¼°ç»“æœ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: åŠ è½½æ•°æ®\n",
        "\n",
        "ä»æ•°æ®åº“è¯»å–ä¸€ä¸ªæœŸè´§å“ç§çš„å†å²æ•°æ®\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º\n",
        "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# è¿æ¥æ•°æ®åº“\n",
        "db_path = Path('../..') / 'database' / 'futures' / 'futures.db'\n",
        "conn = sqlite3.connect(db_path)\n",
        "\n",
        "# è¯»å–èºçº¹é’¢æ•°æ®\n",
        "df = pd.read_sql_query(\"SELECT * FROM hist_rb\", conn)\n",
        "conn.close()\n",
        "\n",
        "# æ•´ç†æ•°æ®\n",
        "df = df.rename(columns={\n",
        "    'trade_date': 'date', 'open_price': 'open', 'high_price': 'high',\n",
        "    'low_price': 'low', 'close_price': 'close'\n",
        "})\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df = df.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "print(f\"æ•°æ®å½¢çŠ¶: {df.shape}\")\n",
        "print(f\"æ—¥æœŸèŒƒå›´: {df['date'].min().date()} ~ {df['date'].max().date()}\")\n",
        "df.tail()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: å®šä¹‰æ ‡ç­¾ (æœ€å…³é”®!)\n",
        "\n",
        "**é—®é¢˜**: ä»€ä¹ˆæ˜¯\"å¥½çš„äº¤æ˜“æœºä¼š\"ï¼Ÿ\n",
        "\n",
        "**æˆ‘ä»¬çš„å®šä¹‰**: å¦‚æœä»Šå¤©ä¹°å…¥ï¼Œæœªæ¥5å¤©å†…æœ€é«˜ä»·æ¶¨å¹… â‰¥ 3%ï¼Œå°±æ˜¯å¥½æœºä¼š (label=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å®šä¹‰å‚æ•°\n",
        "FUTURE_DAYS = 5    # çœ‹æœªæ¥5å¤©\n",
        "THRESHOLD = 0.03   # 3%çš„æ¶¨å¹…é˜ˆå€¼\n",
        "\n",
        "# è®¡ç®—æœªæ¥5å¤©çš„æœ€é«˜ä»·\n",
        "df['future_high'] = df['high'].shift(-1).rolling(FUTURE_DAYS).max().shift(-FUTURE_DAYS + 1)\n",
        "\n",
        "# æœ€å¤§ä¸Šæ¶¨å¹…åº¦\n",
        "df['max_up_return'] = (df['future_high'] - df['close']) / df['close']\n",
        "\n",
        "# ç”Ÿæˆæ ‡ç­¾\n",
        "df['label'] = (df['max_up_return'] >= THRESHOLD).astype(int)\n",
        "\n",
        "# ç»Ÿè®¡\n",
        "print(\"æ ‡ç­¾åˆ†å¸ƒ:\")\n",
        "print(df['label'].value_counts())\n",
        "print(f\"\\næ­£æ ·æœ¬(å¥½æœºä¼š)å æ¯”: {df['label'].mean()*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: åˆ›å»ºç‰¹å¾\n",
        "\n",
        "ç”¨æŠ€æœ¯æŒ‡æ ‡æ¥æè¿°å½“å‰å¸‚åœºçŠ¶æ€\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åˆ›å»º5ä¸ªæ ¸å¿ƒç‰¹å¾\n",
        "close = df['close']\n",
        "high = df['high']\n",
        "low = df['low']\n",
        "volume = df['volume']\n",
        "\n",
        "# 1. åŠ¨é‡: è¿‡å»Nå¤©æ”¶ç›Šç‡\n",
        "df['feat_ret_5'] = close.pct_change(5)\n",
        "df['feat_ret_20'] = close.pct_change(20)\n",
        "\n",
        "# 2. å‡çº¿åç¦»: ä»·æ ¼ç›¸å¯¹å‡çº¿çš„ä½ç½®\n",
        "ma_20 = close.rolling(20).mean()\n",
        "df['feat_ma20_dev'] = (close - ma_20) / ma_20\n",
        "\n",
        "# 3. æ³¢åŠ¨ç‡: ä»·æ ¼æ³¢åŠ¨ç¨‹åº¦\n",
        "df['feat_volatility'] = close.pct_change().rolling(20).std()\n",
        "\n",
        "# 4. ä»·æ ¼ä½ç½®: åœ¨è¿‘æœŸé«˜ä½ç‚¹åŒºé—´çš„ä½ç½® (0=æœ€ä½, 1=æœ€é«˜)\n",
        "high_20 = high.rolling(20).max()\n",
        "low_20 = low.rolling(20).min()\n",
        "df['feat_price_pos'] = (close - low_20) / (high_20 - low_20 + 1e-6)\n",
        "\n",
        "# 5. æˆäº¤é‡æ¯”: ç›¸å¯¹å¹³å‡æˆäº¤é‡\n",
        "vol_ma = volume.rolling(20).mean()\n",
        "df['feat_vol_ratio'] = volume / (vol_ma + 1e-6)\n",
        "\n",
        "# æŸ¥çœ‹ç‰¹å¾\n",
        "feature_cols = [col for col in df.columns if col.startswith('feat_')]\n",
        "print(f\"åˆ›å»ºäº† {len(feature_cols)} ä¸ªç‰¹å¾: {feature_cols}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: åˆ’åˆ†æ•°æ® & è®­ç»ƒæ¨¡å‹\n",
        "\n",
        "æŒ‰æ—¶é—´åˆ’åˆ†: 2022å¹´å‰è®­ç»ƒï¼Œ2023å¹´éªŒè¯ï¼Œ2024å¹´æµ‹è¯•\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç§»é™¤ç¼ºå¤±å€¼\n",
        "df_clean = df.dropna(subset=feature_cols + ['label']).copy()\n",
        "\n",
        "# æŒ‰æ—¶é—´åˆ’åˆ†\n",
        "df_train = df_clean[df_clean['date'] <= '2022-12-31']\n",
        "df_valid = df_clean[(df_clean['date'] > '2022-12-31') & (df_clean['date'] <= '2023-12-31')]\n",
        "df_test = df_clean[df_clean['date'] > '2023-12-31']\n",
        "\n",
        "print(f\"è®­ç»ƒé›†: {len(df_train)} æ ·æœ¬\")\n",
        "print(f\"éªŒè¯é›†: {len(df_valid)} æ ·æœ¬\")\n",
        "print(f\"æµ‹è¯•é›†: {len(df_test)} æ ·æœ¬\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è®­ç»ƒæ¨¡å‹\n",
        "try:\n",
        "    import lightgbm as lgb\n",
        "    model = lgb.LGBMClassifier(n_estimators=100, max_depth=5, verbosity=-1)\n",
        "except ImportError:\n",
        "    from sklearn.ensemble import GradientBoostingClassifier\n",
        "    model = GradientBoostingClassifier(n_estimators=100, max_depth=5)\n",
        "\n",
        "# å‡†å¤‡æ•°æ®\n",
        "X_train, y_train = df_train[feature_cols].values, df_train['label'].values\n",
        "X_valid, y_valid = df_valid[feature_cols].values, df_valid['label'].values\n",
        "X_test, y_test = df_test[feature_cols].values, df_test['label'].values\n",
        "\n",
        "# è®­ç»ƒ\n",
        "model.fit(X_train, y_train)\n",
        "print(\"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: è¯„ä¼°æ¨¡å‹\n",
        "\n",
        "ç”¨å‡ ä¸ªå…³é”®æŒ‡æ ‡æ¥åˆ¤æ–­æ¨¡å‹å¥½ä¸å¥½\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
        "\n",
        "# é¢„æµ‹æ¦‚ç‡\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# ç”¨0.5ä½œä¸ºé˜ˆå€¼åˆ†ç±»\n",
        "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
        "\n",
        "# è®¡ç®—æŒ‡æ ‡\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"ğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœ (æµ‹è¯•é›†)\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\"\"\n",
        "AUC: {auc:.4f}\n",
        "  â†’ è§£è¯»: 0.5=éšæœº, 0.6=ä¸€èˆ¬, 0.7=ä¸é”™, 0.8=å¾ˆå¥½\n",
        "\n",
        "ç²¾ç¡®ç‡ (Precision): {precision*100:.2f}%\n",
        "  â†’ æ¨¡å‹è¯´\"ä¹°\"çš„é‡Œé¢ï¼Œæœ‰å¤šå°‘çœŸçš„æ¶¨äº†?\n",
        "\n",
        "å¬å›ç‡ (Recall): {recall*100:.2f}%\n",
        "  â†’ æ‰€æœ‰æ¶¨çš„æœºä¼šä¸­ï¼Œæ¨¡å‹æŠ“ä½äº†å¤šå°‘?\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: å¯è§†åŒ–ç†è§£\n",
        "\n",
        "çœ‹çœ‹æ¨¡å‹é¢„æµ‹çš„æ¦‚ç‡åˆ†å¸ƒ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# å·¦å›¾: æ¦‚ç‡åˆ†å¸ƒ\n",
        "ax1 = axes[0]\n",
        "ax1.hist(y_pred_proba[y_test==0], bins=30, alpha=0.5, label='å®é™…=0 (æ™®é€š)', density=True)\n",
        "ax1.hist(y_pred_proba[y_test==1], bins=30, alpha=0.5, label='å®é™…=1 (å¥½æœºä¼š)', density=True)\n",
        "ax1.set_xlabel('é¢„æµ‹æ¦‚ç‡')\n",
        "ax1.set_ylabel('å¯†åº¦')\n",
        "ax1.set_title('é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ')\n",
        "ax1.legend()\n",
        "ax1.axvline(x=0.5, color='red', linestyle='--', alpha=0.5, label='é˜ˆå€¼=0.5')\n",
        "\n",
        "# å³å›¾: ç‰¹å¾é‡è¦æ€§\n",
        "ax2 = axes[1]\n",
        "if hasattr(model, 'feature_importances_'):\n",
        "    importance = model.feature_importances_\n",
        "    sorted_idx = np.argsort(importance)\n",
        "    ax2.barh(range(len(sorted_idx)), importance[sorted_idx])\n",
        "    ax2.set_yticks(range(len(sorted_idx)))\n",
        "    ax2.set_yticklabels([feature_cols[i] for i in sorted_idx])\n",
        "    ax2.set_xlabel('é‡è¦æ€§')\n",
        "    ax2.set_title('ç‰¹å¾é‡è¦æ€§')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ’¡ ç‰¹å¾é‡è¦æ€§å‘Šè¯‰ä½ ï¼šæ¨¡å‹è®¤ä¸ºå“ªäº›æŒ‡æ ‡å¯¹é¢„æµ‹æœ€æœ‰ç”¨\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ¯ ç»ƒä¹ : åŠ¨æ‰‹è¯•è¯•\n",
        "\n",
        "### ç»ƒä¹ 1: ä¿®æ”¹é˜ˆå€¼ï¼Œè§‚å¯Ÿæ­£æ ·æœ¬æ¯”ä¾‹å˜åŒ–\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å°è¯•ä¸åŒçš„é˜ˆå€¼\n",
        "print(\"ä¸åŒé˜ˆå€¼ä¸‹çš„æ­£æ ·æœ¬æ¯”ä¾‹:\")\n",
        "print(\"-\" * 40)\n",
        "for thresh in [0.01, 0.02, 0.03, 0.04, 0.05, 0.08, 0.10]:\n",
        "    label = (df_clean['max_up_return'] >= thresh)\n",
        "    ratio = label.mean()\n",
        "    print(f\"é˜ˆå€¼ {thresh*100:4.0f}%: æ­£æ ·æœ¬æ¯”ä¾‹ = {ratio*100:5.2f}%\")\n",
        "\n",
        "print(\"\\nğŸ’¡ é˜ˆå€¼è¶Šé«˜ â†’ æ­£æ ·æœ¬è¶Šå°‘ â†’ æ ‡å‡†è¶Šä¸¥æ ¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ç»ƒä¹ 2: æ·»åŠ ä¸€ä¸ªæ–°ç‰¹å¾ - RSI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RSI (ç›¸å¯¹å¼ºå¼±æŒ‡æ ‡) çš„è®¡ç®—æ–¹æ³•\n",
        "# RSI = 100 - 100 / (1 + RS)\n",
        "# RS = å¹³å‡ä¸Šæ¶¨ / å¹³å‡ä¸‹è·Œ\n",
        "\n",
        "delta = df_clean['close'].diff()\n",
        "gain = delta.where(delta > 0, 0)\n",
        "loss = (-delta).where(delta < 0, 0)\n",
        "\n",
        "avg_gain = gain.rolling(14).mean()\n",
        "avg_loss = loss.rolling(14).mean()\n",
        "\n",
        "rs = avg_gain / (avg_loss + 1e-6)\n",
        "df_clean['feat_rsi'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "print(\"RSI ç»Ÿè®¡:\")\n",
        "print(df_clean['feat_rsi'].describe())\n",
        "print(\"\\nğŸ’¡ RSI < 30 é€šå¸¸è¢«è®¤ä¸ºæ˜¯è¶…å–ï¼ˆå¯èƒ½åå¼¹ï¼‰\")\n",
        "print(\"ğŸ’¡ RSI > 70 é€šå¸¸è¢«è®¤ä¸ºæ˜¯è¶…ä¹°ï¼ˆå¯èƒ½å›è°ƒï¼‰\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ“ æ€»ç»“\n",
        "\n",
        "æ­å–œä½ å®Œæˆäº†å…¥é—¨å®è·µï¼ç°åœ¨ä½ åº”è¯¥ç†è§£äº†ï¼š\n",
        "\n",
        "| æ­¥éª¤ | å…³é”®æ¦‚å¿µ | å¯¹åº”å®Œæ•´ä»£ç  |\n",
        "|------|---------|-------------|\n",
        "| 1. æ•°æ® | Kçº¿æ•°æ®ã€OHLCV | `load_history_from_db()` |\n",
        "| 2. æ ‡ç­¾ | æœªæ¥æœ€å¤§æ¶¨å¹…å®šä¹‰å¥½æœºä¼š | `assign_labels_v2()` |\n",
        "| 3. ç‰¹å¾ | æŠ€æœ¯æŒ‡æ ‡æè¿°å¸‚åœºçŠ¶æ€ | `make_features_v2()` |\n",
        "| 4. æ¨¡å‹ | LightGBM å­¦ä¹ ç‰¹å¾-æ ‡ç­¾å…³ç³» | `train_model()` |\n",
        "| 5. è¯„ä¼° | AUCã€ç²¾ç¡®ç‡ã€å¬å›ç‡ | `analyze_backtest_results()` |\n",
        "\n",
        "### ä¸‹ä¸€æ­¥å­¦ä¹ \n",
        "\n",
        "1. é˜…è¯»å®Œæ•´çš„ `å­¦ä¹ æŒ‡å—_æœºå™¨å­¦ä¹ é‡åŒ–ç­–ç•¥.md`\n",
        "2. è¿è¡Œå®Œæ•´çš„ `futures_trend_ml.py` å¹¶ç†è§£è¾“å‡º\n",
        "3. å°è¯•ä¿®æ”¹å‚æ•°è§‚å¯Ÿç»“æœå˜åŒ–\n",
        "\n",
        "æœ‰é—®é¢˜éšæ—¶é—®ï¼ğŸš€\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
