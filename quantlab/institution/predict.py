#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¯æ—¥é¢„æµ‹è„šæœ¬ï¼šåŸºäºèåˆæ¨¡å‹ç”Ÿæˆäº¤æ˜“ä¿¡å·

ä½¿ç”¨æ–¹æ³•ï¼š
    python predict.py              # æ˜¾ç¤ºä»Šæ—¥ä¿¡å·
    python predict.py --top 10     # æ˜¾ç¤ºå‰10ä¸ªä¿¡å·
    python predict.py --json       # è¾“å‡ºJSONæ ¼å¼

å‰ç½®æ¡ä»¶ï¼š
    1. ç¡®ä¿ database/futures/futures.db å·²æ›´æ–°åˆ°æœ€æ–°æ—¥æœŸ
    2. ç¡®ä¿ database/institution/institution.db å·²æ›´æ–°åˆ°æœ€æ–°æ—¥æœŸ
    3. ç¡®ä¿ models/ ç›®å½•ä¸‹å·²æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹

ä½œè€…ï¼šé‡åŒ–å·¥ç¨‹å¸ˆ
æ—¥æœŸï¼š2024
"""

import json
import sqlite3
import warnings
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple

import joblib
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression

warnings.filterwarnings('ignore')

# ==================================================
# è·¯å¾„é…ç½®
# ==================================================
PROJECT_ROOT = Path(__file__).parent.parent.parent
FUTURES_DB = PROJECT_ROOT / "database" / "futures" / "futures.db"
INSTITUTION_DB = PROJECT_ROOT / "database" / "institution" / "institution.db"
MAPPING_FILE = PROJECT_ROOT / "database" / "institution" / "mapping.json"

MODEL_DIR = Path(__file__).parent / "models"
CONFIG_FILE = MODEL_DIR / "config.json"
LONG_MODEL_FILE = MODEL_DIR / "long_model.pkl"
SHORT_MODEL_FILE = MODEL_DIR / "short_model.pkl"


# ==================================================
# æ•°æ®åŠ è½½
# ==================================================

def load_mapping() -> dict:
    """åŠ è½½æœŸè´§è¡¨ååˆ°æœºæ„æŒä»“è¡¨åçš„æ˜ å°„"""
    with open(MAPPING_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data.get('mappings', {})


def get_futures_data(table_name: str, days: int = 100) -> pd.DataFrame:
    """ä»æœŸè´§æ•°æ®åº“è¯»å–æœ€è¿‘Nå¤©çš„ä»·æ ¼æ•°æ®"""
    conn = sqlite3.connect(FUTURES_DB)
    try:
        table_name_lower = table_name.lower()
        sql = f"""
        SELECT 
            trade_date as date,
            open_price as open,
            high_price as high,
            low_price as low,
            close_price as close,
            volume,
            open_interest
        FROM {table_name_lower}
        ORDER BY trade_date DESC
        LIMIT {days}
        """
        df = pd.read_sql(sql, conn)
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date').reset_index(drop=True)
        return df
    except Exception:
        return pd.DataFrame()
    finally:
        conn.close()


def get_institution_data(variety_name: str, days: int = 100) -> pd.DataFrame:
    """ä»æœºæ„æŒä»“æ•°æ®åº“è¯»å–æœ€è¿‘Nå¤©çš„æŒä»“æ•°æ®"""
    conn = sqlite3.connect(INSTITUTION_DB)
    try:
        cursor = conn.cursor()
        cursor.execute(
            "SELECT name FROM sqlite_master WHERE type='table' AND name=?",
            (variety_name,)
        )
        if not cursor.fetchone():
            return pd.DataFrame()
        
        sql = f"""
        SELECT 
            trade_date as date,
            total_buy,
            total_ss,
            total_buy_chge,
            total_ss_chge
        FROM "{variety_name}"
        ORDER BY trade_date DESC
        LIMIT {days}
        """
        df = pd.read_sql(sql, conn)
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date').reset_index(drop=True)
        return df
    except Exception:
        return pd.DataFrame()
    finally:
        conn.close()


def load_latest_data(min_days: int = 80) -> pd.DataFrame:
    """åŠ è½½æ‰€æœ‰å“ç§çš„æœ€æ–°æ•°æ®"""
    mapping = load_mapping()
    all_data = []
    
    for futures_table, institution_table in mapping.items():
        df_futures = get_futures_data(futures_table, days=100)
        if df_futures.empty:
            continue
        
        df_institution = get_institution_data(institution_table, days=100)
        if df_institution.empty:
            continue
        
        df = pd.merge(df_futures, df_institution, on='date', how='inner')
        
        if len(df) < min_days:
            continue
        
        df['symbol'] = institution_table
        all_data.append(df)
    
    if not all_data:
        raise ValueError("æ²¡æœ‰å¯ç”¨çš„æ•°æ®ï¼è¯·æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å·²æ›´æ–°ã€‚")
    
    df_all = pd.concat(all_data, ignore_index=True)
    df_all = df_all.sort_values(['symbol', 'date']).reset_index(drop=True)
    
    return df_all


# ==================================================
# ç‰¹å¾å·¥ç¨‹ï¼ˆä¸ train.py ä¿æŒä¸€è‡´ï¼‰
# ==================================================

def calculate_atr(df: pd.DataFrame, period: int = 20) -> pd.Series:
    """è®¡ç®— ATR"""
    high, low, close = df['high'], df['low'], df['close']
    tr1 = high - low
    tr2 = abs(high - close.shift(1))
    tr3 = abs(low - close.shift(1))
    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
    return tr.rolling(window=period, min_periods=1).mean()


def compute_trend_features(close: pd.Series, window: int = 10) -> Tuple[pd.Series, pd.Series]:
    """è®¡ç®—è¶‹åŠ¿æ–œç‡å’Œ RÂ²"""
    slopes, r2s = [], []
    
    for i in range(len(close)):
        if i < window - 1:
            slopes.append(np.nan)
            r2s.append(np.nan)
        else:
            y = close.iloc[i-window+1:i+1].values
            x = np.arange(window).reshape(-1, 1)
            
            if np.any(np.isnan(y)):
                slopes.append(np.nan)
                r2s.append(np.nan)
                continue
            
            y_mean, y_std = y.mean(), y.std()
            if y_std < 1e-10:
                slopes.append(0)
                r2s.append(0)
                continue
            
            y_norm = (y - y_mean) / y_std
            model = LinearRegression()
            model.fit(x, y_norm)
            slopes.append(model.coef_[0])
            r2s.append(model.score(x, y_norm))
    
    return pd.Series(slopes, index=close.index), pd.Series(r2s, index=close.index)


def make_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    ç”Ÿæˆèåˆç‰¹å¾ï¼šè¶‹åŠ¿MLå®Œæ•´ç‰¹å¾ + å›½æ³°æŒä»“ç‰¹å¾
    ï¼ˆä¸ train.py ä¸­ make_features_fusion ä¿æŒä¸€è‡´ï¼‰
    """
    df = df.copy()
    feature_dfs = []
    
    for symbol in df['symbol'].unique():
        mask = df['symbol'] == symbol
        df_sym = df[mask].copy()
        
        close = df_sym['close']
        high = df_sym['high']
        low = df_sym['low']
        open_price = df_sym['open']
        volume = df_sym['volume']
        oi = df_sym['open_interest']
        
        # ========================================
        # Part 1: è¶‹åŠ¿MLæŠ€æœ¯ç‰¹å¾
        # ========================================
        
        # 1. ä»·æ ¼åŠ¨é‡
        for period in [3, 5, 10, 20]:
            df_sym[f'feat_ret_{period}'] = close.pct_change(period)
        df_sym['feat_momentum_accel'] = df_sym['feat_ret_5'] - df_sym['feat_ret_5'].shift(5)
        
        # 2. çªç ´ä¿¡å·
        for period in [10, 20, 40]:
            rolling_high = high.rolling(period, min_periods=1).max()
            rolling_low = low.rolling(period, min_periods=1).min()
            range_hl = rolling_high - rolling_low
            
            df_sym[f'feat_price_pos_{period}'] = (close - rolling_low) / (range_hl + 1e-6)
            df_sym[f'feat_break_high_{period}'] = (close >= rolling_high.shift(1)).astype(int)
            df_sym[f'feat_break_low_{period}'] = (close <= rolling_low.shift(1)).astype(int)
            df_sym[f'feat_dist_high_{period}'] = (rolling_high - close) / (close + 1e-6)
            df_sym[f'feat_dist_low_{period}'] = (close - rolling_low) / (close + 1e-6)
        
        # 3. å‡çº¿ç³»ç»Ÿ
        ma_periods = [5, 10, 20, 40, 60]
        for period in ma_periods:
            df_sym[f'MA_{period}'] = close.rolling(period, min_periods=1).mean()
        
        df_sym['feat_ma_align_bull'] = (
            (df_sym['MA_5'] > df_sym['MA_10']) & 
            (df_sym['MA_10'] > df_sym['MA_20']) & 
            (df_sym['MA_20'] > df_sym['MA_40'])
        ).astype(int)
        
        df_sym['feat_ma_align_bear'] = (
            (df_sym['MA_5'] < df_sym['MA_10']) & 
            (df_sym['MA_10'] < df_sym['MA_20']) & 
            (df_sym['MA_20'] < df_sym['MA_40'])
        ).astype(int)
        
        df_sym['feat_price_ma20_dev'] = (close - df_sym['MA_20']) / (df_sym['MA_20'] + 1e-6)
        df_sym['feat_price_ma60_dev'] = (close - df_sym['MA_60']) / (df_sym['MA_60'] + 1e-6)
        
        # 4. æ³¢åŠ¨ç‡ç‰¹å¾
        returns = close.pct_change()
        for period in [5, 10, 20]:
            df_sym[f'feat_vol_{period}'] = returns.rolling(period, min_periods=1).std()
        
        df_sym['feat_vol_contraction'] = df_sym['feat_vol_5'] / (df_sym['feat_vol_20'] + 1e-6)
        df_sym['feat_atr_20'] = calculate_atr(df_sym, period=20)
        df_sym['feat_atr_ratio'] = df_sym['feat_atr_20'] / (close + 1e-6)
        df_sym['feat_atr_change'] = df_sym['feat_atr_20'].pct_change(5)
        
        # 5. è¶‹åŠ¿å¼ºåº¦
        slope_10, r2_10 = compute_trend_features(close, window=10)
        slope_20, r2_20 = compute_trend_features(close, window=20)
        
        df_sym['feat_trend_slope_10'] = slope_10
        df_sym['feat_trend_r2_10'] = r2_10
        df_sym['feat_trend_slope_20'] = slope_20
        df_sym['feat_trend_r2_20'] = r2_20
        df_sym['feat_trend_score_10'] = slope_10 * r2_10
        df_sym['feat_trend_score_20'] = slope_20 * r2_20
        
        # 6. æˆäº¤é‡ç‰¹å¾
        vol_ma_5 = volume.rolling(5, min_periods=1).mean()
        vol_ma_20 = volume.rolling(20, min_periods=1).mean()
        
        df_sym['feat_vol_ratio_5'] = volume / (vol_ma_5 + 1e-6)
        df_sym['feat_vol_ratio_20'] = volume / (vol_ma_20 + 1e-6)
        df_sym['feat_vol_trend'] = vol_ma_5 / (vol_ma_20 + 1e-6)
        df_sym['feat_vol_breakout'] = (
            (volume > vol_ma_20 * 1.5) & 
            (abs(returns) > df_sym['feat_vol_20'])
        ).astype(int)
        
        # 7. æŒä»“é‡ç‰¹å¾
        oi_ma_20 = oi.rolling(20, min_periods=1).mean()
        df_sym['feat_oi_ratio'] = oi / (oi_ma_20 + 1e-6)
        df_sym['feat_oi_chg_5'] = oi.pct_change(5)
        
        price_up = (close > close.shift(1)).astype(int)
        oi_up = (oi > oi.shift(1)).astype(int)
        df_sym['feat_price_oi_bull'] = (price_up & oi_up).astype(int)
        df_sym['feat_price_oi_bear'] = ((1 - price_up) & oi_up).astype(int)
        
        # 8. Kçº¿å½¢æ€
        bar_range = high - low
        body = abs(close - open_price)
        
        df_sym['feat_body_ratio'] = body / (bar_range + 1e-6)
        df_sym['feat_close_pos'] = (close - low) / (bar_range + 1e-6)
        df_sym['feat_consec_up'] = (close > open_price).rolling(3).sum()
        df_sym['feat_consec_down'] = (close < open_price).rolling(3).sum()
        
        # 9. RSI
        delta = close.diff()
        gain = delta.where(delta > 0, 0)
        loss = (-delta).where(delta < 0, 0)
        avg_gain = gain.rolling(14, min_periods=1).mean()
        avg_loss = loss.rolling(14, min_periods=1).mean()
        rs = avg_gain / (avg_loss + 1e-6)
        df_sym['feat_rsi_14'] = 100 - (100 / (1 + rs))
        
        # 10. å¸ƒæ—å¸¦
        ma_20 = df_sym['MA_20']
        std_20 = close.rolling(20, min_periods=1).std()
        upper_band = ma_20 + 2 * std_20
        lower_band = ma_20 - 2 * std_20
        
        df_sym['feat_bb_pos'] = (close - lower_band) / (upper_band - lower_band + 1e-6)
        df_sym['feat_bb_break_up'] = (close > upper_band).astype(int)
        df_sym['feat_bb_break_down'] = (close < lower_band).astype(int)
        
        # ========================================
        # Part 2: å›½æ³°å›å®‰æŒä»“ç‰¹å¾
        # ========================================
        
        total_buy = df_sym['total_buy']
        total_ss = df_sym['total_ss']
        total_buy_chge = df_sym['total_buy_chge']
        total_ss_chge = df_sym['total_ss_chge']
        
        # å‡€æŒä»“
        net_position = total_buy - total_ss
        net_change = total_buy_chge - total_ss_chge
        net_position_prev = net_position.shift(1)
        
        # ä¸»åŠ¨è¿›æ”»ä¿¡å·
        is_long_attack = (net_position > 0) & (net_change > 0)
        is_short_attack = (net_position < 0) & (net_change < 0)
        
        df_sym['feat_gtja_long_attack'] = is_long_attack.astype(int)
        df_sym['feat_gtja_short_attack'] = is_short_attack.astype(int)
        
        # è¿›æ”»å¼ºåº¦
        df_sym['feat_gtja_long_intensity'] = 0.0
        mask_long_valid = is_long_attack & (net_position_prev.abs() > 100)
        df_sym.loc[mask_long_valid, 'feat_gtja_long_intensity'] = (
            net_change[mask_long_valid] / net_position_prev[mask_long_valid].abs()
        )
        
        df_sym['feat_gtja_short_intensity'] = 0.0
        mask_short_valid = is_short_attack & (net_position_prev.abs() > 100)
        df_sym.loc[mask_short_valid, 'feat_gtja_short_intensity'] = (
            net_change[mask_short_valid].abs() / net_position_prev[mask_short_valid].abs()
        )
        
        # è¿›æ”»æŒç»­æ€§
        long_attack_group = (is_long_attack != is_long_attack.shift()).cumsum()
        df_sym['feat_gtja_long_streak'] = df_sym.groupby(long_attack_group)['feat_gtja_long_attack'].cumsum()
        
        short_attack_group = (is_short_attack != is_short_attack.shift()).cumsum()
        df_sym['feat_gtja_short_streak'] = df_sym.groupby(short_attack_group)['feat_gtja_short_attack'].cumsum()
        
        # ç´¯è®¡è¿›æ”»å¼ºåº¦
        df_sym['feat_gtja_long_intensity_3d'] = df_sym['feat_gtja_long_intensity'].rolling(3).sum()
        df_sym['feat_gtja_short_intensity_3d'] = df_sym['feat_gtja_short_intensity'].rolling(3).sum()
        
        # å‡€æŒä»“è§„æ¨¡
        df_sym['feat_gtja_net_ratio'] = net_position / (oi + 1e-6)
        
        # è¿›æ”» Ã— æŠ€æœ¯å…±æŒ¯
        df_sym['feat_gtja_long_with_ma'] = (
            is_long_attack & (df_sym['feat_ma_align_bull'] == 1)
        ).astype(int)
        
        df_sym['feat_gtja_short_with_ma'] = (
            is_short_attack & (df_sym['feat_ma_align_bear'] == 1)
        ).astype(int)
        
        df_sym['feat_gtja_long_with_break'] = (
            is_long_attack & (df_sym['feat_break_high_20'] == 1)
        ).astype(int)
        
        df_sym['feat_gtja_short_with_break'] = (
            is_short_attack & (df_sym['feat_break_low_20'] == 1)
        ).astype(int)
        
        feature_dfs.append(df_sym)
    
    df_feat = pd.concat(feature_dfs, ignore_index=True)
    
    # å¤„ç†æ— ç©·å€¼
    feature_cols = [col for col in df_feat.columns if col.startswith('feat_')]
    for col in feature_cols:
        df_feat[col] = df_feat[col].replace([np.inf, -np.inf], np.nan)
        df_feat[col] = df_feat[col].clip(-1e10, 1e10)
    
    return df_feat


# ==================================================
# é¢„æµ‹æ ¸å¿ƒ
# ==================================================

def load_models():
    """åŠ è½½æ¨¡å‹å’Œé…ç½®"""
    if not LONG_MODEL_FILE.exists():
        raise FileNotFoundError(f"å¤šå¤´æ¨¡å‹ä¸å­˜åœ¨: {LONG_MODEL_FILE}")
    if not SHORT_MODEL_FILE.exists():
        raise FileNotFoundError(f"ç©ºå¤´æ¨¡å‹ä¸å­˜åœ¨: {SHORT_MODEL_FILE}")
    if not CONFIG_FILE.exists():
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {CONFIG_FILE}")
    
    long_model = joblib.load(LONG_MODEL_FILE)
    short_model = joblib.load(SHORT_MODEL_FILE)
    
    with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    return long_model, short_model, config


def predict_today(top_n: int = 10) -> List[Dict]:
    """
    é¢„æµ‹ä»Šæ—¥ä¿¡å·
    
    Returns:
        List[Dict]: æŒ‰ä¿¡å·å¼ºåº¦æ’åºçš„æ¨èåˆ—è¡¨
    """
    # 1. åŠ è½½æ¨¡å‹
    long_model, short_model, config = load_models()
    feature_cols = config['features']
    signal_percentile = config.get('signal_percentile', 95)
    
    print("=" * 60)
    print(f"ğŸ“Š æ¯æ—¥ä¿¡å·é¢„æµ‹ | {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    print("=" * 60)
    print(f"æ¨¡å‹è®­ç»ƒæ—¥æœŸ: {config.get('train_date', 'N/A')}")
    print(f"ä¿¡å·é˜ˆå€¼: Top {100 - signal_percentile:.0f}%")
    
    # 2. åŠ è½½æœ€æ–°æ•°æ®
    print("\n[æ•°æ®] åŠ è½½æœ€æ–°æ•°æ®...")
    df_all = load_latest_data(min_days=80)
    latest_date = df_all['date'].max()
    print(f"[æ•°æ®] æœ€æ–°æ—¥æœŸ: {latest_date.strftime('%Y-%m-%d')}")
    print(f"[æ•°æ®] å“ç§æ•°é‡: {df_all['symbol'].nunique()}")
    
    # 3. ç”Ÿæˆç‰¹å¾
    print("[ç‰¹å¾] è®¡ç®—ç‰¹å¾...")
    df_feat = make_features(df_all)
    
    # 4. å–æ¯ä¸ªå“ç§çš„æœ€æ–°ä¸€æ¡æ•°æ®
    df_latest = df_feat.sort_values('date').groupby('symbol').tail(1).reset_index(drop=True)
    print(f"[é¢„æµ‹] å¾…é¢„æµ‹å“ç§: {len(df_latest)}")
    
    # 5. æ£€æŸ¥ç‰¹å¾å®Œæ•´æ€§
    missing_cols = set(feature_cols) - set(df_latest.columns)
    if missing_cols:
        print(f"[è­¦å‘Š] ç¼ºå°‘ç‰¹å¾: {missing_cols}")
        return []
    
    # 6. å¡«å……NaN
    X = df_latest[feature_cols].fillna(0).values
    
    # 7. é¢„æµ‹
    p_long = long_model.predict_proba(X)[:, 1]
    p_short = short_model.predict_proba(X)[:, 1]
    
    # 8. è®¡ç®—é˜ˆå€¼ï¼ˆä½¿ç”¨å…¨éƒ¨é¢„æµ‹å€¼çš„ç™¾åˆ†ä½æ•°ï¼‰
    long_threshold = np.percentile(p_long, signal_percentile)
    short_threshold = np.percentile(p_short, signal_percentile)
    
    # 9. ç”Ÿæˆä¿¡å·
    signals = []
    for i, row in df_latest.iterrows():
        symbol = row['symbol']
        
        # å¤šå¤´ä¿¡å·
        if p_long[i] >= long_threshold:
            signals.append({
                'symbol': symbol,
                'direction': 'åšå¤š',
                'probability': float(p_long[i]),
                'close': float(row['close']),
                'date': row['date'].strftime('%Y-%m-%d'),
                'gtja_long_attack': int(row.get('feat_gtja_long_attack', 0)),
                'gtja_long_streak': int(row.get('feat_gtja_long_streak', 0)),
                'ma_align_bull': int(row.get('feat_ma_align_bull', 0)),
                'trend_score': float(row.get('feat_trend_score_20', 0)),
            })
        
        # ç©ºå¤´ä¿¡å·
        if p_short[i] >= short_threshold:
            signals.append({
                'symbol': symbol,
                'direction': 'åšç©º',
                'probability': float(p_short[i]),
                'close': float(row['close']),
                'date': row['date'].strftime('%Y-%m-%d'),
                'gtja_short_attack': int(row.get('feat_gtja_short_attack', 0)),
                'gtja_short_streak': int(row.get('feat_gtja_short_streak', 0)),
                'ma_align_bear': int(row.get('feat_ma_align_bear', 0)),
                'trend_score': float(row.get('feat_trend_score_20', 0)),
            })
    
    # 10. æŒ‰æ¦‚ç‡æ’åº
    signals = sorted(signals, key=lambda x: x['probability'], reverse=True)
    
    return signals[:top_n]


def print_signals(signals: List[Dict]) -> None:
    """æ‰“å°ä¿¡å·åˆ—è¡¨"""
    if not signals:
        print("\nâš ï¸ ä»Šæ—¥æ— æ¨èä¿¡å·")
        return
    
    print("\n" + "=" * 60)
    print("ğŸ“ˆ ä»Šæ—¥æ¨èä¿¡å·")
    print("=" * 60)
    
    for i, sig in enumerate(signals, 1):
        direction_emoji = "ğŸ”´ åšå¤š" if sig['direction'] == 'åšå¤š' else "ğŸ”µ åšç©º"
        
        # è¾…åŠ©ä¿¡æ¯
        if sig['direction'] == 'åšå¤š':
            attack = "âœ“ å›½æ³°è¿›æ”»" if sig.get('gtja_long_attack', 0) else ""
            streak = f"è¿ç»­{sig.get('gtja_long_streak', 0)}å¤©" if sig.get('gtja_long_streak', 0) > 0 else ""
            ma_ok = "âœ“ å‡çº¿å¤šæ’" if sig.get('ma_align_bull', 0) else ""
        else:
            attack = "âœ“ å›½æ³°è¿›æ”»" if sig.get('gtja_short_attack', 0) else ""
            streak = f"è¿ç»­{sig.get('gtja_short_streak', 0)}å¤©" if sig.get('gtja_short_streak', 0) > 0 else ""
            ma_ok = "âœ“ å‡çº¿ç©ºæ’" if sig.get('ma_align_bear', 0) else ""
        
        extras = " | ".join(filter(None, [attack, streak, ma_ok]))
        
        print(f"\n{i}. {sig['symbol']} {direction_emoji}")
        print(f"   æ¦‚ç‡: {sig['probability']*100:.1f}% | æ”¶ç›˜ä»·: {sig['close']:.2f}")
        if extras:
            print(f"   {extras}")


# ==================================================
# ä¸»ç¨‹åº
# ==================================================

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ¯æ—¥ä¿¡å·é¢„æµ‹')
    parser.add_argument('--top', type=int, default=10, help='æ˜¾ç¤ºå‰Nä¸ªä¿¡å· (é»˜è®¤: 10)')
    parser.add_argument('--json', action='store_true', help='è¾“å‡ºJSONæ ¼å¼')
    args = parser.parse_args()
    
    try:
        signals = predict_today(top_n=args.top)
        
        if args.json:
            print(json.dumps(signals, ensure_ascii=False, indent=2))
        else:
            print_signals(signals)
            print(f"\nâœ… é¢„æµ‹å®Œæˆï¼Œå…± {len(signals)} ä¸ªä¿¡å·")
    
    except FileNotFoundError as e:
        print(f"âŒ é”™è¯¯: {e}")
        print("è¯·å…ˆè¿è¡Œ train.py è®­ç»ƒæ¨¡å‹")
    except Exception as e:
        print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()

