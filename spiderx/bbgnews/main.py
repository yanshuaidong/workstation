#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Bloomberg æ–°é—»è‡ªåŠ¨å¤„ç†æœåŠ¡

åŠŸèƒ½è¯´æ˜ï¼š
1. æ¥æ”¶æµè§ˆå™¨æ‰©å±•å‘é€çš„æ–°é—»æ•°æ®ï¼ˆFlask APIï¼‰
2. å®šæ—¶å¤„ç†æ–°é—»ï¼ˆæ¯å¤©6/12/18/24ç‚¹ï¼‰
3. AIç­›é€‰ç›¸å…³æ–°é—»å¹¶ç¿»è¯‘æˆä¸­æ–‡
4. ä¿å­˜åˆ°MySQLæ•°æ®åº“ä¸¤ä¸ªè¡¨
5. è‡ªåŠ¨åˆ é™¤å·²å¤„ç†çš„æœ¬åœ°æ•°æ®

å·¥ä½œæµç¨‹ï¼š
æ’ä»¶å‘é€ -> æœ¬åœ°å­˜å‚¨ -> å®šæ—¶è§¦å‘ -> AIç­›é€‰ -> æ•°æ®åº“ä¿å­˜ -> åˆ é™¤æœ¬åœ°æ•°æ®
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
from apscheduler.schedulers.background import BackgroundScheduler
import json
import os
import time
import pymysql
import requests
import signal
import sys
from datetime import datetime, timedelta
import logging

# ==================== é…ç½®éƒ¨åˆ† ====================

# Flaskåº”ç”¨é…ç½®
app = Flask(__name__)
CORS(app)

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('bloomberg_service.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# æ•°æ®æ–‡ä»¶é…ç½®
DATA_DIR = 'captured_data'
DATA_FILE = os.path.join(DATA_DIR, 'bloomberg_news.json')

# AI API é…ç½®ï¼ˆå†™æ­»åœ¨ä»£ç é‡Œï¼‰
AI_API_KEY = "sk-qVU4OZNspU5cSTPONFBFD000t2Oy8Tq9U8h74Wm5Phnl8tsB"
AI_BASE_URL = "https://poloai.top/v1/chat/completions"

# æ•°æ®åº“é…ç½®ï¼ˆå†™æ­»åœ¨ä»£ç é‡Œï¼‰
DB_CONFIG = {
    'host': 'rm-bp1u701yzm0y42oh1vo.mysql.rds.aliyuncs.com',
    'port': 3306,
    'user': 'ysd',
    'password': 'Yan1234567',
    'database': 'futures',
    'charset': 'utf8mb4'
}

# æœåŠ¡ç«¯å£
SERVICE_PORT = 1123

# ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)

# ==================== æ•°æ®åº“æ“ä½œ ====================

def get_db_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    return pymysql.connect(**DB_CONFIG)

def save_to_database(title, content, ctime):
    """
    ä¿å­˜æ–°é—»åˆ°æ•°æ®åº“ä¸¤ä¸ªè¡¨
    
    å‚æ•°ï¼š
        title: æ–°é—»æ ‡é¢˜
        content: AIç­›é€‰åçš„å†…å®¹
        ctime: æ–°é—»å‘ç”Ÿæ—¶é—´çš„æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
    
    è¿”å›ï¼š
        bool: æ˜¯å¦æˆåŠŸ
    """
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # 1. æ’å…¥æ–°é—»è¡¨ news_red_telegraph
        insert_news_sql = """
            INSERT INTO news_red_telegraph 
            (ctime, title, content, ai_analysis, message_score, message_label, message_type)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
        """
        cursor.execute(insert_news_sql, (
            ctime,
            title,
            content,
            'æš‚æ— åˆ†æ',
            6,
            'hard',
            'å½­åšç¤¾æ–°é—»'
        ))
        
        # è·å–æ’å…¥çš„æ–°é—»ID
        news_id = cursor.lastrowid
        
        # 2. æ’å…¥è·Ÿè¸ªè¡¨ news_process_trackingï¼ˆä½¿ç”¨é»˜è®¤å€¼ï¼‰
        insert_tracking_sql = """
            INSERT INTO news_process_tracking (news_id, ctime)
            VALUES (%s, %s)
        """
        cursor.execute(insert_tracking_sql, (news_id, ctime))
        
        conn.commit()
        logger.info(f"âœ… æ•°æ®åº“ä¿å­˜æˆåŠŸ - æ–°é—»ID: {news_id}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“ä¿å­˜å¤±è´¥: {e}")
        if conn:
            conn.rollback()
        return False
    finally:
        if conn:
            cursor.close()
            conn.close()

# ==================== AIæ¥å£è°ƒç”¨ ====================

def call_ai_api(news_list, max_retries=2):
    """
    è°ƒç”¨AIæ¥å£ç­›é€‰æ–°é—»ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
    
    å‚æ•°ï¼š
        news_list: æ–°é—»åˆ—è¡¨
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤2æ¬¡ï¼‰
    
    è¿”å›ï¼š
        str or None: AIè¿”å›çš„ç­›é€‰ç»“æœï¼Œå¤±è´¥è¿”å›None
    """
    # æ„å»ºæç¤ºè¯
    news_json = json.dumps(news_list, ensure_ascii=False, indent=2)
    
    system_message = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èæ–°é—»ç­›é€‰å’Œç¿»è¯‘åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. ä»ç»™å®šçš„æ–°é—»åˆ—è¡¨ä¸­ç­›é€‰å‡ºä¸æœŸè´§æˆ–è‚¡ç¥¨å¸‚åœºç›¸å…³çš„æ–°é—»
2. å°†ç­›é€‰å‡ºçš„æ–°é—»æ ‡é¢˜ç¿»è¯‘æˆä¸­æ–‡
3. æŒ‰ç…§æŒ‡å®šæ ¼å¼è¾“å‡ºç»“æœ

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
1ã€[ä¸­æ–‡ç¿»è¯‘çš„æ–°é—»æ ‡é¢˜1]
2ã€[ä¸­æ–‡ç¿»è¯‘çš„æ–°é—»æ ‡é¢˜2]
3ã€[ä¸­æ–‡ç¿»è¯‘çš„æ–°é—»æ ‡é¢˜3]
...

æ³¨æ„ï¼š
- åªè¾“å‡ºä¸æœŸè´§æˆ–è‚¡ç¥¨ç›¸å…³çš„æ–°é—»
- å¦‚æœæ²¡æœ‰ç›¸å…³æ–°é—»ï¼Œè¾“å‡ºï¼šæ— ç›¸å…³æ–°é—»
- æ¯æ¡æ–°é—»ç‹¬å ä¸€è¡Œï¼ŒæŒ‰åºå·æ’åˆ—
- ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„è§£é‡Šæˆ–åˆ†æ"""

    user_message = f"""è¯·ç­›é€‰ä»¥ä¸‹æ–°é—»ä¸­ä¸æœŸè´§æˆ–è‚¡ç¥¨å¸‚åœºç›¸å…³çš„å†…å®¹ï¼Œå¹¶ç¿»è¯‘æˆä¸­æ–‡ï¼š

{news_json}"""

    # é‡è¯•é…ç½®
    timeouts = [60, 120]  # ç¬¬ä¸€æ¬¡60ç§’ï¼Œç¬¬äºŒæ¬¡120ç§’
    
    for attempt in range(max_retries):
        try:
            timeout = timeouts[attempt] if attempt < len(timeouts) else timeouts[-1]
            logger.info(f"ğŸ¤– è°ƒç”¨AIæ¥å£ (ç¬¬{attempt + 1}æ¬¡å°è¯•ï¼Œè¶…æ—¶{timeout}ç§’)...")
            
            payload = {
                "model": "gpt-4.1-mini",
                "messages": [
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": user_message}
                ],
                "temperature": 0.7,
                "max_tokens": 5000
            }
            
            headers = {
                "Accept": "application/json",
                "Authorization": f"Bearer {AI_API_KEY}",
                "Content-Type": "application/json"
            }
            
            response = requests.post(AI_BASE_URL, json=payload, headers=headers, timeout=timeout)
            response.raise_for_status()
            
            result = response.json()["choices"][0]["message"]["content"]
            logger.info(f"âœ… AIæ¥å£è°ƒç”¨æˆåŠŸ (ç¬¬{attempt + 1}æ¬¡å°è¯•)")
            return result
            
        except Exception as e:
            logger.error(f"âŒ AIæ¥å£è°ƒç”¨å¤±è´¥ (ç¬¬{attempt + 1}æ¬¡å°è¯•): {e}")
            if attempt == max_retries - 1:
                logger.error("âŒ AIæ¥å£è°ƒç”¨æœ€ç»ˆå¤±è´¥ï¼Œå·²ç”¨å°½æ‰€æœ‰é‡è¯•æ¬¡æ•°")
                return None
            time.sleep(2)  # é‡è¯•å‰ç­‰å¾…2ç§’
    
    return None

# ==================== æ•°æ®æ–‡ä»¶æ“ä½œ ====================

def load_news_data():
    """åŠ è½½æœ¬åœ°æ–°é—»æ•°æ®"""
    if not os.path.exists(DATA_FILE):
        return []
    
    try:
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data if isinstance(data, list) else []
    except Exception as e:
        logger.error(f"âŒ åŠ è½½æ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
        return []

def save_news_data(news_list):
    """ä¿å­˜æ–°é—»æ•°æ®åˆ°æœ¬åœ°æ–‡ä»¶"""
    try:
        with open(DATA_FILE, 'w', encoding='utf-8') as f:
            json.dump(news_list, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜æ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
        return False

def add_news_item(news_item):
    """æ·»åŠ æ–°é—»æ¡ç›®ï¼ˆå¸¦å»é‡ï¼‰"""
    news_list = load_news_data()
    
    # å»é‡ï¼šæ ¹æ® publishedAt åˆ¤æ–­
    existing_times = {item.get('publishedAt') for item in news_list}
    
    if news_item.get('publishedAt') not in existing_times:
        news_list.append(news_item)
        save_news_data(news_list)
        return True
    return False

def delete_news_in_timerange(start_time, end_time):
    """
    åˆ é™¤æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„æ–°é—»
    
    å‚æ•°ï¼š
        start_time: å¼€å§‹æ—¶é—´ï¼ˆdatetimeå¯¹è±¡ï¼‰
        end_time: ç»“æŸæ—¶é—´ï¼ˆdatetimeå¯¹è±¡ï¼‰
    """
    news_list = load_news_data()
    original_count = len(news_list)
    
    # è¿‡æ»¤æ‰æ—¶é—´èŒƒå›´å†…çš„æ–°é—»
    filtered_list = []
    for item in news_list:
        local_time_str = item.get('localReceivedTime', '')
        if local_time_str:
            try:
                local_time = datetime.fromisoformat(local_time_str)
                # ä¿ç•™ä¸åœ¨åˆ é™¤èŒƒå›´å†…çš„æ–°é—»
                if not (start_time <= local_time < end_time):
                    filtered_list.append(item)
            except:
                # å¦‚æœæ—¶é—´è§£æå¤±è´¥ï¼Œä¿ç•™è¯¥æ¡æ–°é—»
                filtered_list.append(item)
        else:
            # æ²¡æœ‰æœ¬åœ°æ—¶é—´çš„æ–°é—»ä¹Ÿä¿ç•™
            filtered_list.append(item)
    
    deleted_count = original_count - len(filtered_list)
    save_news_data(filtered_list)
    logger.info(f"ğŸ—‘ï¸ åˆ é™¤äº† {deleted_count} æ¡æ–°é—» (åŸæœ‰{original_count}æ¡ï¼Œå‰©ä½™{len(filtered_list)}æ¡)")

# ==================== å®šæ—¶ä»»åŠ¡ ====================

def process_news_task():
    """
    å®šæ—¶ä»»åŠ¡ï¼šå¤„ç†æ–°é—»
    åœ¨ 6/12/18/24 ç‚¹æ‰§è¡Œ
    """
    now = datetime.now()
    current_hour = now.hour
    
    # ç¡®å®šå¤„ç†çš„æ—¶é—´æ®µ
    if current_hour == 6:
        start_hour, end_hour = 0, 6
        time_label = "0ç‚¹åˆ°6ç‚¹"
    elif current_hour == 12:
        start_hour, end_hour = 6, 12
        time_label = "6ç‚¹åˆ°12ç‚¹"
    elif current_hour == 18:
        start_hour, end_hour = 12, 18
        time_label = "12ç‚¹åˆ°18ç‚¹"
    elif current_hour == 0:
        start_hour, end_hour = 18, 24
        time_label = "18ç‚¹åˆ°24ç‚¹"
    else:
        logger.warning(f"âš ï¸ éé¢„æœŸçš„æ‰§è¡Œæ—¶é—´: {current_hour}ç‚¹")
        return
    
    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸ• å¼€å§‹å¤„ç† {now.strftime('%Yå¹´%mæœˆ%dæ—¥')} {time_label} çš„æ–°é—»")
    logger.info(f"{'='*60}")
    
    # è®¡ç®—æ—¶é—´èŒƒå›´
    start_time = now.replace(hour=start_hour, minute=0, second=0, microsecond=0)
    if end_hour == 24:
        end_time = (start_time + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
    else:
        end_time = now.replace(hour=end_hour, minute=0, second=0, microsecond=0)
    
    # åŠ è½½æ‰€æœ‰æ–°é—»
    all_news = load_news_data()
    
    # ç­›é€‰æ—¶é—´èŒƒå›´å†…çš„æ–°é—»
    target_news = []
    for item in all_news:
        local_time_str = item.get('localReceivedTime', '')
        if local_time_str:
            try:
                local_time = datetime.fromisoformat(local_time_str)
                if start_time <= local_time < end_time:
                    target_news.append(item)
            except Exception as e:
                logger.warning(f"âš ï¸ æ—¶é—´è§£æå¤±è´¥: {e}")
    
    logger.info(f"ğŸ“Š æ‰¾åˆ° {len(target_news)} æ¡å¾…å¤„ç†æ–°é—»")
    
    if len(target_news) == 0:
        logger.info("â„¹ï¸ æ²¡æœ‰éœ€è¦å¤„ç†çš„æ–°é—»")
        logger.info(f"{'='*60}\n")
        return
    
    # å‡†å¤‡å‘é€ç»™AIçš„æ–°é—»åˆ—è¡¨ï¼ˆåªåŒ…å«å¿…è¦å­—æ®µï¼‰
    news_for_ai = [
        {
            'publishedAt': item.get('publishedAt'),
            'headline': item.get('headline'),
            'brand': item.get('brand', '')
        }
        for item in target_news
    ]
    
    # è°ƒç”¨AIæ¥å£ç­›é€‰
    ai_result = call_ai_api(news_for_ai)
    
    if ai_result is None:
        logger.error("âŒ AIç­›é€‰å¤±è´¥ï¼Œæœ¬æ¬¡ä»»åŠ¡ç»ˆæ­¢")
        logger.info(f"{'='*60}\n")
        return
    
    # æ„å»ºæ ‡é¢˜å’Œå†…å®¹
    date_str = now.strftime('%Yå¹´%mæœˆ%dæ—¥')
    title = f"ã€å½­åšç¤¾{date_str}{time_label}æ–°é—»ã€‘"
    content = ai_result.strip()
    
    # è®¡ç®— ctimeï¼ˆä½¿ç”¨æ—¶é—´æ®µçš„å¼€å§‹æ—¶é—´ä½œä¸ºæ–°é—»å‘ç”Ÿæ—¶é—´ï¼‰
    ctime = int(start_time.timestamp())
    
    logger.info(f"ğŸ“ æ ‡é¢˜: {title}")
    logger.info(f"ğŸ“„ å†…å®¹é¢„è§ˆ: {content[:100]}...")
    
    # ä¿å­˜åˆ°æ•°æ®åº“
    success = save_to_database(title, content, ctime)
    
    if success:
        # åˆ é™¤å·²å¤„ç†çš„æ–°é—»
        delete_news_in_timerange(start_time, end_time)
        logger.info("âœ… æ–°é—»å¤„ç†å®Œæˆ")
    else:
        logger.error("âŒ æ•°æ®åº“ä¿å­˜å¤±è´¥ï¼Œä¸åˆ é™¤æœ¬åœ°æ•°æ®")
    
    logger.info(f"{'='*60}\n")

# ==================== Flaskè·¯ç”± ====================

@app.route('/api/capture', methods=['POST', 'OPTIONS'])
def capture_data():
    """æ¥æ”¶æµè§ˆå™¨æ‰©å±•å‘é€çš„æ–°é—»æ•°æ®"""
    
    if request.method == 'OPTIONS':
        return '', 200
    
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'message': 'æ²¡æœ‰æ¥æ”¶åˆ°æ•°æ®'
            }), 400
        
        # è·å–æ–°é—»åˆ—è¡¨
        captured_data = data.get('capturedData', [])
        
        if not captured_data:
            return jsonify({
                'success': False,
                'message': 'æ•°æ®åˆ—è¡¨ä¸ºç©º'
            }), 400
        
        # å½“å‰æœ¬åœ°æ—¶é—´
        local_time = datetime.now().isoformat()
        
        # æ·»åŠ æ–°é—»åˆ°æœ¬åœ°å­˜å‚¨
        added_count = 0
        for item in captured_data:
            # ä¸ºæ¯æ¡æ–°é—»æ·»åŠ æœ¬åœ°æ¥æ”¶æ—¶é—´
            news_item = {
                'publishedAt': item.get('publishedAt'),
                'headline': item.get('headline'),
                'brand': item.get('brand', ''),
                'localReceivedTime': local_time  # æ·»åŠ æœ¬åœ°æ¥æ”¶æ—¶é—´
            }
            
            if add_news_item(news_item):
                added_count += 1
        
        # è·å–å½“å‰æ€»æ•°
        all_news = load_news_data()
        total_count = len(all_news)
        
        logger.info(f'âœ… æ–°é—»æ¥æ”¶æˆåŠŸ - æ–°å¢: {added_count} æ¡ | æ€»è®¡: {total_count} æ¡')
        
        return jsonify({
            'success': True,
            'message': 'æ•°æ®ä¿å­˜æˆåŠŸ',
            'added': added_count,
            'total': total_count
        }), 200
        
    except Exception as e:
        logger.error(f'âŒ æ•°æ®æ¥æ”¶å¤±è´¥: {e}')
        return jsonify({
            'success': False,
            'message': f'ä¿å­˜å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    news_list = load_news_data()
    return jsonify({
        'status': 'ok',
        'service': 'Bloombergæ–°é—»å¤„ç†æœåŠ¡',
        'port': 1123,
        'time': datetime.now().isoformat(),
        'pending_news': len(news_list)
    })

@app.route('/api/stats', methods=['GET'])
def get_stats():
    """è·å–ç»Ÿè®¡ä¿¡æ¯"""
    news_list = load_news_data()
    return jsonify({
        'total': len(news_list),
        'file': DATA_FILE
    })

@app.route('/api/process_now', methods=['POST'])
def process_now():
    """æ‰‹åŠ¨è§¦å‘å¤„ç†ä»»åŠ¡ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    try:
        process_news_task()
        return jsonify({
            'success': True,
            'message': 'å¤„ç†ä»»åŠ¡å·²æ‰§è¡Œ'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        }), 500

# ==================== ä¸»ç¨‹åº ====================

# å…¨å±€å˜é‡
scheduler = None
shutdown_flag = False

def signal_handler(signum, frame):
    """ä¿¡å·å¤„ç†å™¨ï¼Œç”¨äºä¼˜é›…é€€å‡º"""
    global shutdown_flag
    signal_name = signal.Signals(signum).name
    logger.info(f"æ”¶åˆ°ä¿¡å· {signal_name}ï¼Œå‡†å¤‡ä¼˜é›…é€€å‡º...")
    print(f"\nğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å· {signal_name}ï¼Œæ­£åœ¨å®‰å…¨åœæ­¢æœåŠ¡...")
    
    shutdown_flag = True
    
    # åœæ­¢è°ƒåº¦å™¨
    if scheduler:
        logger.info("æ­£åœ¨åœæ­¢å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨...")
        scheduler.shutdown(wait=False)
        logger.info("å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²åœæ­¢")
    
    logger.info("æœåŠ¡å·²å®‰å…¨åœæ­¢")
    sys.exit(0)

if __name__ == '__main__':
    logger.info('='*60)
    logger.info('ğŸš€ Bloombergæ–°é—»å¤„ç†æœåŠ¡å¯åŠ¨')
    logger.info(f'ğŸ“ ç›‘å¬ç«¯å£: {SERVICE_PORT}')
    logger.info(f'ğŸ’¾ æ•°æ®æ–‡ä»¶: {os.path.abspath(DATA_FILE)}')
    logger.info(f'ğŸ”— æ¥æ”¶æ¥å£: http://localhost:{SERVICE_PORT}/api/capture')
    logger.info(f'ğŸ’š å¥åº·æ£€æŸ¥: http://localhost:{SERVICE_PORT}/api/health')
    logger.info(f'ğŸ“Š ç»Ÿè®¡ä¿¡æ¯: http://localhost:{SERVICE_PORT}/api/stats')
    logger.info('='*60)
    
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)   # Ctrl+C
    signal.signal(signal.SIGTERM, signal_handler)  # killå‘½ä»¤
    logger.info("âœ… ä¿¡å·å¤„ç†å™¨å·²æ³¨å†Œ")
    
    # å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
    scheduler = BackgroundScheduler()
    
    # æ·»åŠ å®šæ—¶ä»»åŠ¡ï¼šæ¯å¤©çš„ 6ã€12ã€18ã€0 ç‚¹æ‰§è¡Œ
    scheduler.add_job(process_news_task, 'cron', hour='6,12,18,0', minute=0)
    
    scheduler.start()
    logger.info('â° å®šæ—¶ä»»åŠ¡å·²å¯åŠ¨ (æ¯å¤©6ç‚¹ã€12ç‚¹ã€18ç‚¹ã€24ç‚¹æ‰§è¡Œ)')
    
    # æ‰“å°ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
    jobs = scheduler.get_jobs()
    if jobs:
        next_run_time = jobs[0].next_run_time
        logger.info(f'ğŸ“… ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´: {next_run_time.strftime("%Y-%m-%d %H:%M:%S")}')
    
    try:
        # å¯åŠ¨FlaskæœåŠ¡
        app.run(host='0.0.0.0', port=SERVICE_PORT, debug=False, use_reloader=False)
    except (KeyboardInterrupt, SystemExit):
        if scheduler:
            scheduler.shutdown()
        logger.info('ğŸ‘‹ æœåŠ¡å·²åœæ­¢')
