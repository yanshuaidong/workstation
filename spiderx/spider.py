import time
import json
import os
import sys
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import requests
import logging
from datetime import datetime
import re

# é…ç½®æ—¥å¿—
log_file = '/app/logs/spider.log' if os.path.exists('/app/logs') else 'spider.log'
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(log_file, encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

class ClsSpider:
    def __init__(self, headless=True, server_mode=False):
        self.driver = None
        self.headless = headless
        self.server_mode = server_mode or self.detect_server_environment()
        self.network_logs = []
        self.collected_data = []
        
        # æœåŠ¡å™¨æ¨¡å¼å¼ºåˆ¶æ— å¤´è¿è¡Œ
        if self.server_mode:
            self.headless = True
            logger.info("æ£€æµ‹åˆ°æœåŠ¡å™¨ç¯å¢ƒï¼Œå¼ºåˆ¶å¯ç”¨æ— å¤´æ¨¡å¼")
        
    def detect_server_environment(self):
        """æ£€æµ‹æ˜¯å¦åœ¨æœåŠ¡å™¨ç¯å¢ƒä¸­è¿è¡Œ"""
        # æ£€æŸ¥æ˜¯å¦åœ¨Dockerå®¹å™¨ä¸­
        if os.path.exists('/.dockerenv'):
            return True
            
        # æ£€æŸ¥æ˜¯å¦æœ‰DISPLAYç¯å¢ƒå˜é‡ï¼ˆLinuxå›¾å½¢ç¯å¢ƒï¼‰
        if os.name == 'posix' and not os.environ.get('DISPLAY'):
            return True
            
        # æ£€æŸ¥æ˜¯å¦åœ¨CI/CDç¯å¢ƒä¸­
        ci_vars = ['CI', 'CONTINUOUS_INTEGRATION', 'GITHUB_ACTIONS', 'GITLAB_CI']
        if any(os.environ.get(var) for var in ci_vars):
            return True
            
        return False
        
    def setup_driver(self):
        """è®¾ç½®Chromeé©±åŠ¨ - æœåŠ¡å™¨ä¼˜åŒ–ç‰ˆ"""
        chrome_options = Options()
        
        # å¼ºåˆ¶æ— å¤´æ¨¡å¼
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--disable-extensions')
        chrome_options.add_argument('--disable-plugins')
        chrome_options.add_argument('--disable-images')
        chrome_options.add_argument('--disable-javascript')  # å¦‚æœä¸éœ€è¦JSå¯ä»¥ç¦ç”¨
        chrome_options.add_argument('--disable-css')  # ç¦ç”¨CSSåŠ è½½
        
        # æœåŠ¡å™¨ç¯å¢ƒä¸“ç”¨é€‰é¡¹
        chrome_options.add_argument('--remote-debugging-port=9222')
        chrome_options.add_argument('--disable-background-timer-throttling')
        chrome_options.add_argument('--disable-backgrounding-occluded-windows')
        chrome_options.add_argument('--disable-renderer-backgrounding')
        chrome_options.add_argument('--disable-features=TranslateUI')
        chrome_options.add_argument('--disable-ipc-flooding-protection')
        chrome_options.add_argument('--disable-background-networking')
        chrome_options.add_argument('--disable-default-apps')
        chrome_options.add_argument('--disable-sync')
        chrome_options.add_argument('--metrics-recording-only')
        chrome_options.add_argument('--no-first-run')
        chrome_options.add_argument('--safebrowsing-disable-auto-update')
        chrome_options.add_argument('--disable-web-security')
        chrome_options.add_argument('--allow-running-insecure-content')
        
        # è®¾ç½®çª—å£å¤§å°
        chrome_options.add_argument('--window-size=1920,1080')
        
        # ç”¨æˆ·ä»£ç†
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        # å¯ç”¨ç½‘ç»œæ—¥å¿—è®°å½•
        chrome_options.add_argument('--enable-logging')
        chrome_options.add_argument('--log-level=0')
        chrome_options.set_capability('goog:loggingPrefs', {'performance': 'ALL'})
        
        # å†…å­˜å’Œæ€§èƒ½ä¼˜åŒ–
        chrome_options.add_argument('--memory-pressure-off')
        chrome_options.add_argument('--max_old_space_size=4096')
        
        # å°è¯•ä¸åŒçš„Chromeè·¯å¾„
        chrome_paths = [
            '/usr/bin/google-chrome-stable',  # Docker/Linux
            '/usr/bin/google-chrome',
            '/usr/bin/chromium-browser',
            '/usr/bin/chromium',
            r"C:\Program Files\Google\Chrome\Application\chrome.exe",  # Windows
            r"C:\Program Files (x86)\Google\Chrome\Application\chrome.exe",
        ]
        
        chrome_found = False
        for chrome_path in chrome_paths:
            if os.path.exists(chrome_path):
                logger.info(f"æ‰¾åˆ°Chromeæµè§ˆå™¨: {chrome_path}")
                chrome_options.binary_location = chrome_path
                chrome_found = True
                break
        
        if not chrome_found:
            logger.warning("æœªæ‰¾åˆ°Chromeæµè§ˆå™¨äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œå°è¯•ä½¿ç”¨ç³»ç»Ÿé»˜è®¤è·¯å¾„")
        
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥ä½¿ç”¨Chrome
            self.driver = webdriver.Chrome(options=chrome_options)
            logger.info("Chromeé©±åŠ¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"ç›´æ¥ä½¿ç”¨Chromeå¤±è´¥: {e}")
            try:
                # ä½¿ç”¨webdriver-managerä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
                from webdriver_manager.chrome import ChromeDriverManager
                service = Service(ChromeDriverManager().install())
                self.driver = webdriver.Chrome(service=service, options=chrome_options)
                logger.info("ä½¿ç”¨webdriver-manageråˆå§‹åŒ–Chromeé©±åŠ¨æˆåŠŸ")
            except Exception as e2:
                logger.error(f"Chromeé©±åŠ¨åˆå§‹åŒ–å¤±è´¥: {e2}")
                logger.error("è¯·ç¡®ä¿å·²å®‰è£…Chromeæµè§ˆå™¨æˆ–åœ¨Dockerä¸­ä½¿ç”¨æ­£ç¡®çš„åŸºç¡€é•œåƒ")
                raise
        
        # è®¾ç½®è¶…æ—¶æ—¶é—´
        self.driver.set_page_load_timeout(30)
        self.driver.implicitly_wait(10)
    
    def get_network_logs(self):
        """è·å–ç½‘ç»œè¯·æ±‚æ—¥å¿—"""
        try:
            logs = self.driver.get_log('performance')
            network_requests = []
            
            for log in logs:
                try:
                    message = json.loads(log['message'])
                    if message['message']['method'] == 'Network.responseReceived':
                        url = message['message']['params']['response']['url']
                        if 'cls.cn/v1/roll/get_roll_list' in url:
                            network_requests.append({
                                'url': url,
                                'timestamp': log['timestamp'],
                                'response': message['message']['params']['response']
                            })
                    elif message['message']['method'] == 'Network.requestWillBeSent':
                        url = message['message']['params']['request']['url']
                        if 'cls.cn/v1/roll/get_roll_list' in url:
                            network_requests.append({
                                'url': url,
                                'timestamp': log['timestamp'],
                                'request': message['message']['params']['request']
                            })
                except (json.JSONDecodeError, KeyError) as e:
                    logger.debug(f"è§£æç½‘ç»œæ—¥å¿—å¤±è´¥: {e}")
                    continue
            
            return network_requests
        except Exception as e:
            logger.error(f"è·å–ç½‘ç»œæ—¥å¿—å¤±è´¥: {e}")
            return []
    
    def extract_params_from_url(self, url):
        """ä»URLä¸­æå–æ‰€æœ‰å‚æ•°"""
        params = {}
        if '?' in url:
            query_string = url.split('?')[1]
            for param in query_string.split('&'):
                if '=' in param:
                    key, value = param.split('=', 1)
                    params[key] = value
        return params
    
    def click_jiahong_button(self):
        """ç‚¹å‡»"åŠ çº¢"æŒ‰é’®çš„æœåŠ¡å™¨ä¼˜åŒ–ç‰ˆæœ¬"""
        logger.info("å¼€å§‹å¯»æ‰¾å¹¶ç‚¹å‡»'åŠ çº¢'æŒ‰é’®...")
        
        # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
        try:
            WebDriverWait(self.driver, 15).until(
                lambda driver: driver.execute_script("return document.readyState") == "complete"
            )
        except Exception as e:
            logger.warning(f"ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆå¤±è´¥: {e}")
        
        # å¤šç§é€‰æ‹©å™¨ç­–ç•¥
        selectors = [
            # åŸºäºæ–‡æœ¬å†…å®¹çš„é€‰æ‹©å™¨
            "//a[contains(text(), 'åŠ çº¢')]",
            "//h3[contains(@class, 'level-2-nav')]//a[contains(text(), 'åŠ çº¢')]",
            "//h3[@class='f-l f-s-17 level-2-nav']//a[@class='p-r d-b w-94 c-p c-ef9524']",
            
            # åŸºäºclassçš„é€‰æ‹©å™¨
            "//a[@class='p-r d-b w-94 c-p c-ef9524']",
            "//a[contains(@class, 'c-ef9524')]",
            
            # æ›´å¹¿æ³›çš„æœç´¢
            "//*[contains(@class, 'level-2-nav')]//*[contains(text(), 'åŠ çº¢')]",
            "//nav//*[contains(text(), 'åŠ çº¢')]",
            "//*[@class='telegraph-nav']//*[contains(text(), 'åŠ çº¢')]",
            
            # CSSé€‰æ‹©å™¨å¤‡é€‰
            "h3.level-2-nav a",
            "a.c-ef9524",
            ".telegraph-nav a[href*='red']"
        ]
        
        for i, selector in enumerate(selectors):
            try:
                logger.info(f"å°è¯•é€‰æ‹©å™¨ {i+1}: {selector}")
                
                if selector.startswith('//') or selector.startswith('/'):
                    # XPathé€‰æ‹©å™¨
                    elements = self.driver.find_elements(By.XPATH, selector)
                else:
                    # CSSé€‰æ‹©å™¨
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                
                if elements:
                    element = elements[0]
                    element_info = {
                        'tag': element.tag_name,
                        'text': element.text[:50],
                        'class': element.get_attribute('class'),
                        'href': element.get_attribute('href')
                    }
                    logger.info(f"æ‰¾åˆ°å…ƒç´ : {element_info}")
                    
                    # æ»šåŠ¨åˆ°å…ƒç´ ä½ç½®
                    try:
                        self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", element)
                        time.sleep(1)
                    except Exception as e:
                        logger.debug(f"æ»šåŠ¨åˆ°å…ƒç´ å¤±è´¥: {e}")
                    
                    # å°è¯•å¤šç§ç‚¹å‡»æ–¹å¼
                    click_methods = [
                        lambda: element.click(),
                        lambda: self.driver.execute_script("arguments[0].click();", element),
                        lambda: self.driver.execute_script("arguments[0].dispatchEvent(new MouseEvent('click', {bubbles: true}));", element)
                    ]
                    
                    for j, click_method in enumerate(click_methods):
                        try:
                            click_method()
                            logger.info(f"æˆåŠŸç‚¹å‡»'åŠ çº¢'æŒ‰é’® (æ–¹æ³• {j+1})")
                            return True
                        except Exception as click_error:
                            logger.debug(f"ç‚¹å‡»æ–¹æ³• {j+1} å¤±è´¥: {click_error}")
                            continue
                else:
                    logger.debug(f"é€‰æ‹©å™¨ {i+1} æœªæ‰¾åˆ°å…ƒç´ ")
                    
            except Exception as e:
                logger.warning(f"é€‰æ‹©å™¨ {i+1} æ‰§è¡Œå¤±è´¥: {e}")
                continue
        
        # æœ€åå°è¯•ï¼šæŸ¥æ‰¾æ‰€æœ‰é“¾æ¥ä¸­åŒ…å«"çº¢"å­—çš„å…ƒç´ 
        try:
            logger.info("å°è¯•æŸ¥æ‰¾æ‰€æœ‰åŒ…å«'çº¢'å­—çš„é“¾æ¥...")
            all_links = self.driver.find_elements(By.TAG_NAME, "a")
            for link in all_links:
                text = link.text.strip()
                href = link.get_attribute('href') or ''
                if ('çº¢' in text or 'red' in text.lower() or 'red' in href.lower()) and len(text) < 10:
                    logger.info(f"æ‰¾åˆ°å¯èƒ½çš„ç›®æ ‡é“¾æ¥: '{text}', href: {href}")
                    try:
                        self.driver.execute_script("arguments[0].click();", link)
                        logger.info(f"æˆåŠŸç‚¹å‡»é“¾æ¥: '{text}'")
                        return True
                    except Exception as e:
                        logger.debug(f"ç‚¹å‡»é“¾æ¥å¤±è´¥: {e}")
                        continue
        except Exception as e:
            logger.warning(f"æŸ¥æ‰¾é“¾æ¥å¤±è´¥: {e}")
        
        logger.error("æœªèƒ½æ‰¾åˆ°æˆ–ç‚¹å‡»'åŠ çº¢'æŒ‰é’®")
        return False
    
    def format_news_data(self, news_item):
        """æ ¼å¼åŒ–æ–°é—»æ•°æ®"""
        try:
            title = news_item.get('title', 'æ— æ ‡é¢˜')
            content = news_item.get('content', news_item.get('brief', 'æ— å†…å®¹'))
            time_str = news_item.get('time', '')
            ctime = news_item.get('ctime', '')
            
            # æ ¼å¼åŒ–æ—¶é—´
            if ctime:
                try:
                    dt = datetime.fromtimestamp(int(ctime))
                    formatted_time = dt.strftime('%Y-%m-%d %H:%M:%S')
                except:
                    formatted_time = time_str or ctime
            else:
                formatted_time = time_str
            
            # æ¸…ç†HTMLæ ‡ç­¾
            content = re.sub(r'<[^>]+>', '', content)
            title = re.sub(r'<[^>]+>', '', title)
            
            return {
                'title': title,
                'content': content,
                'time': formatted_time,
                'original_time': ctime,
                'raw_data': news_item
            }
        except Exception as e:
            logger.warning(f"æ ¼å¼åŒ–æ–°é—»æ•°æ®å¤±è´¥: {e}")
            return {
                'title': 'æ•°æ®è§£æå¤±è´¥',
                'content': str(news_item),
                'time': '',
                'original_time': '',
                'raw_data': news_item
            }
    
    def save_data_to_txt(self, data, filename_prefix="è´¢è”ç¤¾ç”µæŠ¥æ•°æ®"):
        """ä¿å­˜æ•°æ®åˆ°txtæ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # å¦‚æœåœ¨Dockerç¯å¢ƒä¸­ï¼Œä¿å­˜åˆ°dataç›®å½•
        if self.server_mode and os.path.exists('/app/data'):
            filename = f"/app/data/{filename_prefix}_{timestamp}.txt"
        else:
            filename = f"{filename_prefix}_{timestamp}.txt"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write("=" * 80 + "\n")
                f.write(f"è´¢è”ç¤¾ç”µæŠ¥æ•°æ®é‡‡é›†æŠ¥å‘Š\n")
                f.write(f"é‡‡é›†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"è¿è¡Œç¯å¢ƒ: {'Docker/æœåŠ¡å™¨' if self.server_mode else 'æœ¬åœ°'}\n")
                f.write("=" * 80 + "\n\n")
                
                if 'api_data' in data:
                    for i, api_item in enumerate(data['api_data']):
                        f.write(f"ã€APIè¯·æ±‚ {i+1}ã€‘\n")
                        f.write(f"URL: {api_item.get('url', 'N/A')}\n")
                        f.write(f"Sign: {api_item.get('sign', 'N/A')}\n")
                        f.write(f"Last Time: {api_item.get('last_time', 'N/A')}\n")
                        f.write(f"æ—¶é—´æˆ³: {api_item.get('timestamp', 'N/A')}\n")
                        f.write("-" * 60 + "\n")
                        
                        if api_item.get('data') and 'data' in api_item['data']:
                            roll_data = api_item['data']['data'].get('roll_data', [])
                            f.write(f"æ–°é—»æ•°æ® ({len(roll_data)}æ¡):\n\n")
                            
                            for j, news in enumerate(roll_data):
                                formatted_news = self.format_news_data(news)
                                f.write(f"  æ–°é—» {j+1}:\n")
                                f.write(f"    æ ‡é¢˜: {formatted_news['title']}\n")
                                f.write(f"    æ—¶é—´: {formatted_news['time']}\n")
                                f.write(f"    å†…å®¹: {formatted_news['content'][:200]}{'...' if len(formatted_news['content']) > 200 else ''}\n")
                                f.write(f"    å®Œæ•´å†…å®¹: {formatted_news['content']}\n")
                                f.write("    " + "-" * 50 + "\n")
                        
                        f.write("\n" + "=" * 80 + "\n\n")
                
                # ä¿å­˜åŸå§‹JSONæ•°æ®
                f.write("ã€åŸå§‹JSONæ•°æ®ã€‘\n")
                f.write(json.dumps(data, ensure_ascii=False, indent=2))
                
            logger.info(f"æ•°æ®å·²ä¿å­˜åˆ°: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"ä¿å­˜æ•°æ®åˆ°txtæ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def get_page_data(self, url="https://www.cls.cn/telegraph"):
        """è·å–é¡µé¢æ•°æ®å’Œç½‘ç»œè¯·æ±‚ - æœåŠ¡å™¨ä¼˜åŒ–ç‰ˆ"""
        try:
            logger.info(f"è®¿é—®é¡µé¢: {url}")
            self.driver.get(url)
            
            # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
            try:
                WebDriverWait(self.driver, 20).until(
                    EC.presence_of_element_located((By.TAG_NAME, "body"))
                )
                logger.info("é¡µé¢bodyå…ƒç´ åŠ è½½å®Œæˆ")
            except TimeoutException:
                logger.warning("ç­‰å¾…é¡µé¢åŠ è½½è¶…æ—¶ï¼Œç»§ç»­æ‰§è¡Œ...")
            
            logger.info("é¡µé¢åŠ è½½å®Œæˆï¼Œç­‰å¾…6ç§’è¿›è¡Œå……åˆ†åŠ è½½...")
            time.sleep(6)  # æŒ‰éœ€æ±‚æ–‡æ¡£ç­‰å¾…6ç§’
            
            # è·å–é¡µé¢åŸºæœ¬ä¿¡æ¯
            try:
                page_title = self.driver.title
                current_url = self.driver.current_url
                logger.info(f"é¡µé¢æ ‡é¢˜: {page_title}")
                logger.info(f"å½“å‰URL: {current_url}")
            except Exception as e:
                logger.warning(f"è·å–é¡µé¢ä¿¡æ¯å¤±è´¥: {e}")
            
            # å°è¯•ç‚¹å‡»"åŠ çº¢"æŒ‰é’®
            click_success = self.click_jiahong_button()
            
            if click_success:
                logger.info("ç‚¹å‡»æˆåŠŸï¼Œç­‰å¾…ç½‘ç»œè¯·æ±‚...")
                time.sleep(5)  # ç­‰å¾…APIè¯·æ±‚å®Œæˆ
            else:
                logger.warning("ç‚¹å‡»å¤±è´¥ï¼Œç»§ç»­å°è¯•å…¶ä»–æ–¹å¼è§¦å‘è¯·æ±‚...")
                # å°è¯•æ»šåŠ¨å’Œå…¶ä»–æ“ä½œæ¥è§¦å‘è¯·æ±‚
                try:
                    self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                    time.sleep(3)
                    self.driver.execute_script("window.scrollTo(0, 0);")
                    time.sleep(2)
                    
                    # å°è¯•åˆ·æ–°é¡µé¢
                    logger.info("å°è¯•åˆ·æ–°é¡µé¢...")
                    self.driver.refresh()
                    time.sleep(5)
                except Exception as e:
                    logger.warning(f"é¡µé¢æ“ä½œå¤±è´¥: {e}")
            
            # è·å–é¡µé¢HTML
            html_content = self.driver.page_source
            logger.info(f"è·å–åˆ°HTMLå†…å®¹ï¼Œé•¿åº¦: {len(html_content)}")
            
            # è·å–ç½‘ç»œè¯·æ±‚æ—¥å¿—
            network_requests = self.get_network_logs()
            logger.info(f"æ•è·åˆ° {len(network_requests)} ä¸ªç½‘ç»œè¯·æ±‚")
            
            # å¤„ç†APIæ•°æ®
            api_data = []
            for request in network_requests:
                url = request['url']
                params = self.extract_params_from_url(url)
                
                if params.get('sign'):
                    logger.info(f"å‘ç°APIè¯·æ±‚ï¼Œsign: {params.get('sign')}, last_time: {params.get('last_time')}")
                    api_item = {
                        'url': url,
                        'sign': params.get('sign'),
                        'last_time': params.get('last_time'),
                        'app': params.get('app'),
                        'category': params.get('category'),
                        'timestamp': request['timestamp'],
                        'all_params': params
                    }
                    
                    # å°è¯•ä½¿ç”¨ç›¸åŒçš„è¯·æ±‚å‚æ•°è·å–æ•°æ®
                    try:
                        response = self.make_api_request(url)
                        if response:
                            api_item['data'] = response
                            if 'data' in response and 'roll_data' in response['data']:
                                news_count = len(response['data']['roll_data'])
                                logger.info(f"æˆåŠŸè·å–APIæ•°æ®ï¼ŒåŒ…å« {news_count} æ¡æ–°é—»è®°å½•")
                            else:
                                logger.info("è·å–åˆ°APIå“åº”ï¼Œä½†æ•°æ®æ ¼å¼å¯èƒ½ä¸åŒ")
                    except Exception as e:
                        logger.warning(f"APIè¯·æ±‚å¤±è´¥: {e}")
                        api_item['error'] = str(e)
                    
                    api_data.append(api_item)
            
            # å¦‚æœæ²¡æœ‰è·å–åˆ°APIæ•°æ®ï¼Œä¿å­˜HTMLç”¨äºè°ƒè¯•
            if not api_data:
                if self.server_mode and os.path.exists('/app/data'):
                    debug_file = f"/app/data/debug_html_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
                else:
                    debug_file = f"debug_html_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
                try:
                    with open(debug_file, 'w', encoding='utf-8') as f:
                        f.write(html_content)
                    logger.info(f"è°ƒè¯•HTMLå·²ä¿å­˜åˆ°: {debug_file}")
                except Exception as e:
                    logger.warning(f"ä¿å­˜è°ƒè¯•HTMLå¤±è´¥: {e}")
            
            return {
                'html': html_content,
                'network_requests': network_requests,
                'api_data': api_data,
                'success': len(api_data) > 0,
                'page_title': page_title if 'page_title' in locals() else '',
                'current_url': current_url if 'current_url' in locals() else url
            }
            
        except Exception as e:
            logger.error(f"è·å–é¡µé¢æ•°æ®å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return None
    
    def make_api_request(self, url):
        """ä½¿ç”¨æµè§ˆå™¨çš„cookieså’Œheaderså‘èµ·APIè¯·æ±‚"""
        try:
            # è·å–æµè§ˆå™¨çš„cookies
            cookies = self.driver.get_cookies()
            cookie_dict = {cookie['name']: cookie['value'] for cookie in cookies}
            
            # è®¾ç½®è¯·æ±‚å¤´ï¼ˆæŒ‰ç…§éœ€æ±‚æ–‡æ¡£ä¸­çš„headersï¼‰
            headers = {
                'Accept': 'application/json, text/plain, */*',
                'Accept-Language': 'zh-CN,zh;q=0.9',
                'Cache-Control': 'no-cache',
                'Connection': 'keep-alive',
                'Content-Type': 'application/json;charset=utf-8',
                'Pragma': 'no-cache',
                'Referer': 'https://www.cls.cn/telegraph',
                'Sec-Fetch-Dest': 'empty',
                'Sec-Fetch-Mode': 'cors',
                'Sec-Fetch-Site': 'same-origin',
                'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'sec-ch-ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
                'sec-ch-ua-mobile': '?0',
                'sec-ch-ua-platform': '"Linux"'
            }
            
            logger.info(f"å‘èµ·APIè¯·æ±‚: {url[:100]}...")
            response = requests.get(url, headers=headers, cookies=cookie_dict, timeout=15)
            response.raise_for_status()
            
            json_data = response.json()
            logger.info("APIè¯·æ±‚æˆåŠŸ")
            return json_data
            
        except Exception as e:
            logger.error(f"APIè¯·æ±‚å¤±è´¥: {e}")
            return None
    
    def monitor_real_time(self, duration=60):
        """å®æ—¶ç›‘æ§ç½‘ç»œè¯·æ±‚"""
        logger.info(f"å¼€å§‹å®æ—¶ç›‘æ§ï¼ŒæŒç»­{duration}ç§’")
        
        start_time = time.time()
        collected_data = []
        processed_signs = set()
        
        while time.time() - start_time < duration:
            try:
                # è·å–æ–°çš„ç½‘ç»œæ—¥å¿—
                logs = self.driver.get_log('performance')
                
                for log in logs:
                    try:
                        message = json.loads(log['message'])
                        if message['message']['method'] == 'Network.responseReceived':
                            url = message['message']['params']['response']['url']
                            if 'cls.cn/v1/roll/get_roll_list' in url:
                                params = self.extract_params_from_url(url)
                                sign = params.get('sign')
                                
                                if sign and sign not in processed_signs:
                                    processed_signs.add(sign)
                                    logger.info(f"å®æ—¶æ•è·APIè¯·æ±‚ï¼Œsign: {sign}")
                                    
                                    # å°è¯•è·å–å“åº”æ•°æ®
                                    api_response = self.make_api_request(url)
                                    collected_data.append({
                                        'timestamp': time.time(),
                                        'url': url,
                                        'sign': sign,
                                        'params': params,
                                        'data': api_response
                                    })
                    except (json.JSONDecodeError, KeyError):
                        continue
                
                # æ¨¡æ‹Ÿç”¨æˆ·æ´»åŠ¨ä»¥è§¦å‘æ›´å¤šè¯·æ±‚
                if int(time.time() - start_time) % 15 == 0:  # æ¯15ç§’æ´»åŠ¨ä¸€æ¬¡
                    try:
                        # éšæœºæ»šåŠ¨
                        scroll_height = self.driver.execute_script("return Math.floor(Math.random() * document.body.scrollHeight);")
                        self.driver.execute_script(f"window.scrollTo(0, {scroll_height});")
                        time.sleep(1)
                        
                        # å°è¯•å†æ¬¡ç‚¹å‡»åŠ çº¢æŒ‰é’®
                        if int(time.time() - start_time) % 30 == 0:  # æ¯30ç§’ç‚¹å‡»ä¸€æ¬¡
                            self.click_jiahong_button()
                            time.sleep(2)
                    except Exception as e:
                        logger.debug(f"ç”¨æˆ·æ´»åŠ¨æ¨¡æ‹Ÿå¤±è´¥: {e}")
                
                time.sleep(1)  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"ç›‘æ§è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                time.sleep(1)
        
        return collected_data
    
    def close(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.driver:
            try:
                self.driver.quit()
                logger.info("æµè§ˆå™¨å·²å…³é—­")
            except Exception as e:
                logger.warning(f"å…³é—­æµè§ˆå™¨æ—¶å‡ºé”™: {e}")

def main():
    # æ£€æµ‹è¿è¡Œç¯å¢ƒ
    server_mode = os.path.exists('/.dockerenv') or not os.environ.get('DISPLAY')
    
    if server_mode:
        print("ğŸ³ æ£€æµ‹åˆ°Docker/æœåŠ¡å™¨ç¯å¢ƒ")
        print("=" * 60)
        print("ğŸ•·ï¸  è´¢è”ç¤¾æ— å¤´æµè§ˆå™¨çˆ¬è™« (æœåŠ¡å™¨ç‰ˆ)")
        print("=" * 60)
        show_browser = False
    else:
        print("=" * 60)
        print("ğŸ•·ï¸  è´¢è”ç¤¾æ— å¤´æµè§ˆå™¨çˆ¬è™«")
        print("=" * 60)
        print("æ­¤ç¨‹åºå°†æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨ç¯å¢ƒè®¿é—®è´¢è”ç¤¾ç½‘ç«™")
        print("è·å–'åŠ çº¢'æ–°é—»æ•°æ®å¹¶ä¿å­˜åˆ°txtæ–‡ä»¶")
        print()
        
        show_browser = input("æ˜¯å¦æ˜¾ç¤ºæµè§ˆå™¨ç•Œé¢ï¼Ÿ(y/N): ").lower().strip() == 'y'
    
    spider = ClsSpider(headless=not show_browser, server_mode=server_mode)
    
    try:
        # åˆå§‹åŒ–æµè§ˆå™¨
        logger.info("æ­£åœ¨åˆå§‹åŒ–æµè§ˆå™¨...")
        spider.setup_driver()
        
        # è·å–é¡µé¢æ•°æ®
        logger.info("å¼€å§‹è·å–è´¢è”ç¤¾ç”µæŠ¥é¡µé¢æ•°æ®...")
        result = spider.get_page_data()
        
        if result and result.get('success'):
            logger.info("ğŸ‰ æ•°æ®è·å–æˆåŠŸ!")
            logger.info(f"ğŸ“„ HTMLå†…å®¹é•¿åº¦: {len(result['html'])}")
            logger.info(f"ğŸŒ ç½‘ç»œè¯·æ±‚æ•°é‡: {len(result['network_requests'])}")
            logger.info(f"ğŸ“Š APIæ•°æ®æ•°é‡: {len(result['api_data'])}")
            
            # ä¿å­˜æ•°æ®åˆ°txtæ–‡ä»¶
            txt_file = spider.save_data_to_txt(result)
            if txt_file:
                print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {txt_file}")
                
                # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹æ•°æ®
                total_news = 0
                for api_item in result['api_data']:
                    if api_item.get('data') and 'data' in api_item['data']:
                        roll_data = api_item['data']['data'].get('roll_data', [])
                        total_news += len(roll_data)
                        
                        print(f"\nğŸ“ˆ APIæ•°æ®é¢„è§ˆ:")
                        print(f"   Sign: {api_item['sign']}")
                        print(f"   åˆ†ç±»: {api_item.get('category', 'N/A')}")
                        print(f"   æ–°é—»æ¡æ•°: {len(roll_data)}")
                        
                        # æ˜¾ç¤ºå‰2æ¡æ–°é—»æ ‡é¢˜
                        for i, news in enumerate(roll_data[:2]):
                            formatted_news = spider.format_news_data(news)
                            print(f"   ğŸ“° {i+1}. {formatted_news['title'][:60]}...")
                        
                        if len(roll_data) > 2:
                            print(f"   ... è¿˜æœ‰ {len(roll_data)-2} æ¡æ–°é—»")
                        break
                
                print(f"\nğŸ“Š æ€»è®¡è·å–æ–°é—»: {total_news} æ¡")
            
            # åœ¨æœåŠ¡å™¨æ¨¡å¼ä¸‹ä¸è¯¢é—®å®æ—¶ç›‘æ§
            if not server_mode:
                # è¯¢é—®æ˜¯å¦è¿›è¡Œå®æ—¶ç›‘æ§
                print()
                monitor_choice = input("ğŸ”„ æ˜¯å¦è¿›è¡Œå®æ—¶ç›‘æ§ï¼Ÿ(y/N): ").lower().strip()
                if monitor_choice == 'y':
                    duration = input("â±ï¸  ç›‘æ§æ—¶é•¿ï¼ˆç§’ï¼Œé»˜è®¤30ï¼‰: ").strip()
                    try:
                        duration = int(duration) if duration else 30
                    except ValueError:
                        duration = 30
                    
                    logger.info("å¼€å§‹å®æ—¶ç›‘æ§...")
                    real_time_data = spider.monitor_real_time(duration=duration)
                    
                    if real_time_data:
                        # ä¿å­˜å®æ—¶æ•°æ®
                        realtime_result = {'api_data': real_time_data}
                        realtime_file = spider.save_data_to_txt(realtime_result, "è´¢è”ç¤¾å®æ—¶ç›‘æ§æ•°æ®")
                        print(f"\nğŸ’¾ å®æ—¶ç›‘æ§æ•°æ®å·²ä¿å­˜åˆ°: {realtime_file}")
                        print(f"ğŸ“Š å®æ—¶æ•è·: {len(real_time_data)} æ¡è®°å½•")
        
        elif result:
            logger.warning("âš ï¸  è·å–åˆ°é¡µé¢æ•°æ®ä½†æœªæ‰¾åˆ°APIè¯·æ±‚")
            logger.info("å¯èƒ½éœ€è¦æ‰‹åŠ¨æ£€æŸ¥é¡µé¢ç»“æ„æˆ–è°ƒæ•´ç­–ç•¥")
            
            # ä»ç„¶ä¿å­˜HTMLç”¨äºè°ƒè¯•
            if server_mode and os.path.exists('/app/data'):
                html_file = f"/app/data/debug_html_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
            else:
                html_file = f"debug_html_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(result['html'])
            print(f"ğŸ” è°ƒè¯•HTMLå·²ä¿å­˜åˆ°: {html_file}")
        
        else:
            logger.error("âŒ æœªèƒ½è·å–é¡µé¢æ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œç½‘ç«™è®¿é—®æƒé™")
        
    except Exception as e:
        logger.error(f"ğŸ’¥ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
    
    finally:
        spider.close()
        print("\nğŸ”š ç¨‹åºæ‰§è¡Œå®Œæˆ")

if __name__ == "__main__":
    main()
